{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cf9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import os\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b5be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8810d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account = pd.read_csv('All_Fake_without_debunkers_Updated.csv')\n",
    "df_account_small = df_account[['User_ID', 'UserDescription', 'party', 'Political']].dropna(subset = ['UserDescription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f5813",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "df_acc_manual_pol1 = pd.read_csv(current_dir + '/Political Account Manual Label 1.csv', dtype = 'str')\n",
    "df_acc_manual_pol2 = pd.read_csv(current_dir + '/Political Account Manual Label 2.csv', dtype = 'str')\n",
    "df_acc_manual_pol3 = pd.read_csv(current_dir + '/Political Account Manual Label 3.csv', dtype = 'str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_manual_pol3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475f654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_manual_pol = pd.concat([df_acc_manual_pol1[['User_ID', 'Political', 'Party']],df_acc_manual_pol2[['User_ID', 'Political', 'Party']], df_acc_manual_pol3[['User_ID', 'Political', 'Party']]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657bd4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_manual_pol = df_acc_manual_pol.replace('Non political', 'Non Political')\n",
    "df_acc_manual_pol = df_acc_manual_pol.replace('Undetermined ', 'Undetermined')\n",
    "df_acc_manual_pol.Party = df_acc_manual_pol.Party.replace('Non political', 'No')\n",
    "df_acc_manual_pol.loc[df_acc_manual_pol.Party == 'Non Political', 'Party'] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c23cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_manual_pol.User_ID = df_acc_manual_pol.User_ID.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ad7734",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = set(df_account.loc[df_account.Political == 'Political'].User_ID)\n",
    "s2 = set(df_acc_manual_pol.User_ID)\n",
    "updated_list = list(s1.intersection(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc98deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_account.loc[df_account.Political == 'Political'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79917c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol_niva = df_account.loc[df_account.Political == 'Political']\n",
    "df_pol_niva = df_pol_niva[~df_pol_niva.User_ID.isin(updated_list)][['User_ID', 'Political', 'party']].rename(columns = {'party': 'Party'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba269fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_political_all = pd.concat([df_acc_manual_pol, df_pol_niva])\n",
    "df_acc_political_all = df_acc_political_all.reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30398be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e2e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_imp = df_account[['User_ID','UserName', 'ScreenName',                             \n",
    "                             'UserDescription', 'UserURL', 'UserFollowers', 'UserFriends',\n",
    "           'UserFavoriteCount', 'UserVerified', 'TotalStatus','AccountAgeinDays', 'AveragePosts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7088056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.merge(df_acc_political_all, df_account_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.groupby('Political').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28d5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_account = pd.read_csv('Non_Political_Info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_account['date'] = pd.to_datetime(df_non_account['Created_At'])\n",
    "df_non_account['date'] = df_non_account['date'].dt.strftime('%b %d, %Y')\n",
    "df_non_account['date'] = pd.to_datetime(df_non_account['date']).dt.tz_localize('UTC')\n",
    "df_non_account['Account_Age'] = (pd.Timestamp.now(tz='UTC') - df_non_account['date']).dt.days\n",
    "df_non_account['AveragePosts'] = df_non_account.Post_Count/ df_non_account.Account_Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb4e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_account = df_non_account[['User_ID', 'ScreenName', 'UserName',\n",
    "       'User_Description', 'Favorite_Count', 'Follower_Count',\n",
    "       'Friend_Count', 'Blue_Verified', 'Post_Count', 'URL2', 'Account_Age', 'AveragePosts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06933798",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_account = df_non_account.rename(columns = {'User_Description': 'UserDescription', 'URL2':'UserURL',\n",
    "                                                 'Follower_Count': 'UserFollowers', 'Friend_Count': 'UserFriends', \n",
    "                                                 'Favorite_Count': 'UserFavoriteCount', 'Blue_Verified': 'UserVerified',\n",
    "                                                 'Post_Count': 'TotalStatus', 'Account_Age': 'AccountAgeinDays'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6a8025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2116a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_account['Political'] = 'Non Political'\n",
    "df_non_account['Party'] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac65fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([df_new, df_non_account])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac9422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short = df_new[df_new.Party.isin(['AAP', 'ABVP','BJP', 'INC', 'No', 'RJD', 'RSS',\n",
    "                                       'SP', 'SS', 'Undetermined', 'VHP', 'GOV', 'AIMIM', \n",
    "                                        'DMK', 'SS', 'TSP'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5855736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short = df_new_short.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea12b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_url = pd.read_csv('user_url.csv')\n",
    "df_new_short2=pd.merge(df_new_short, df_user_url[['User_ID', 'Expanded_URL']], on = 'User_ID', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a956b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb59c41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short2['Expanded_URL'] = df_new_short2['Expanded_URL'].fillna(df_new_short2['UserURL'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87b44f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short2['Expanded_URL'] = df_new_short2.Expanded_URL.replace(np.nan, 'No URL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96722d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_new_short2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67dd459",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_list = ['bjp', 'inc', 'modi', 'rahul', 'gandhi', 'yogi', 'congress', 'aap', 'kejriwal', \n",
    "              'भाजपा','भारतीय राष्ट्रीय कांग्रेस', 'मोदी' ,'राहुल','गांधी' ,'योगी','कांग्रेस' ,'आप', 'केजरीवाल' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aac94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short2['UserDescription_lower'] = df_new_short2['UserDescription'].str.lower()\n",
    "df_new_short2['UserName_lower'] = df_new_short2['UserName'].str.lower()\n",
    "df_new_short2['ScreenName_lower'] = df_new_short2['ScreenName'].str.lower()\n",
    "df_new_short2['Expanded_URL_lower'] = df_new_short2['Expanded_URL'].str.lower()\n",
    "df_new_short2.UserDescription_lower = df_new_short2.UserDescription_lower.replace(np.nan, 'No Description')\n",
    "for keyword in keywords_list:\n",
    "    df_new_short2[keyword + '_count_description'] = df_new_short2['UserDescription_lower'].str.count(keyword)\n",
    "    df_new_short2[keyword + '_count_screenname'] = df_new_short2['ScreenName_lower'].str.count(keyword)\n",
    "    df_new_short2[keyword + '_count_url'] = df_new_short2['Expanded_URL_lower'].str.count(keyword)\n",
    "    df_new_short2[keyword + '_count_username'] = df_new_short2['UserName_lower'].str.count(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8b1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short2.UserDescription_lower = df_new_short2.UserDescription_lower.replace(np.nan, 'No Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d91e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyword in keywords_list:\n",
    "    df_new_short2[keyword + '_count_description'] = df_new_short2['UserDescription_lower'].str.count(keyword)\n",
    "    df_new_short2[keyword + '_count_screenname'] = df_new_short2['ScreenName_lower'].str.count(keyword)\n",
    "    df_new_short2[keyword + '_count_url'] = df_new_short2['Expanded_URL_lower'].str.count(keyword)\n",
    "    df_new_short2[keyword + '_count_username'] = df_new_short2['UserName_lower'].str.count(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d740270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_links(text):\n",
    "    return re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "\n",
    "df_new_short2['UserDescription_lower'] = df_new_short2['UserDescription_lower'].apply(remove_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a4654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_tweet = pd.read_csv('/disk/mnemo/users/SBERT All Embedding/User_Data_All/Latest_Tweet_Fake_Spreader.csv',  lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "xwe = list(set(df_pol_all_tweet.User_ID.tolist()))\n",
    "keywords_list = ['bjp', 'inc', 'modi', 'rahul', 'gandhi', 'yogi', 'congress', 'aap', 'kejriwal', \n",
    "              'भाजपा','भारतीय राष्ट्रीय कांग्रेस', 'मोदी' ,'राहुल','गांधी' ,'योगी','कांग्रेस' ,'आप', 'केजरीवाल' ]\n",
    "df_user_tweet_keyword = pd.read_csv('Tweet_Keyword.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41922de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_tweet_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_tweet_keyword.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96926efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonPolitical_tweets = pd.read_csv('Non_Political_Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a7b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonPolitical_tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0d88e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_list = ['bjp', 'inc', 'modi', 'rahul', 'gandhi', 'yogi', 'congress', 'aap', 'kejriwal', \n",
    "              'भाजपा','भारतीय राष्ट्रीय कांग्रेस', 'मोदी' ,'राहुल','गांधी' ,'योगी','कांग्रेस' ,'आप', 'केजरीवाल' ]\n",
    "\n",
    "keyword_counts = {}\n",
    "\n",
    "df_nonPolitical_tweets['Tweet_Text_small'] = df_nonPolitical_tweets['text'].str.lower()\n",
    "\n",
    "for user_id, tweet_text in df_nonPolitical_tweets[['User_ID', 'Tweet_Text_small']].values:\n",
    "    user_keyword_counts = {keyword: 0 for keyword in keywords_list}\n",
    "    \n",
    "    if pd.notna(tweet_text):\n",
    "        for keyword in keywords_list:\n",
    "            user_keyword_counts[keyword] = tweet_text.count(keyword)\n",
    "    \n",
    "    keyword_counts[user_id] = user_keyword_counts\n",
    "\n",
    "result_df = pd.DataFrame.from_dict(keyword_counts, orient='index')\n",
    "\n",
    "result_df.reset_index(inplace=True)\n",
    "result_df.rename(columns={'index': 'User_ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c4185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cbd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.columns = ['User_ID'] + [col + '_Tweets' for col in result_df.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a7a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db2b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_user_tweet_keyword,result_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccf4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_new_short2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35e5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "abcsd = pd.concat([df_user_tweet_keyword,result_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86253e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(abcsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45d0501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5164aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short3 = pd.merge(df_new_short2, abcsd, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eeb255",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_new_short3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6445d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short3 = df_new_short3.replace(np.nan, 0)\n",
    "bjp_keyword_user = ['bjp_count_description', 'bjp_count_screenname', 'bjp_count_url','bjp_count_username',\n",
    "                   'modi_count_description','modi_count_screenname', 'modi_count_url', 'modi_count_username',\n",
    "                   'yogi_count_description','yogi_count_screenname', 'yogi_count_url','yogi_count_username', \n",
    "                   'भाजपा_count_description', 'भाजपा_count_screenname', 'भाजपा_count_url','भाजपा_count_username',\n",
    "                   'मोदी_count_description','मोदी_count_screenname', 'मोदी_count_url', 'मोदी_count_username',\n",
    "                   'योगी_count_description', 'योगी_count_screenname', 'योगी_count_url','योगी_count_username']\n",
    "\n",
    "bjp_keyword_tweet = [ 'bjp_Tweets','modi_Tweets','yogi_Tweets', 'भाजपा_Tweets', 'मोदी_Tweets','योगी_Tweets' ]\n",
    "\n",
    "\n",
    "inc_keyword_user = ['inc_count_description', 'inc_count_screenname','inc_count_url', 'inc_count_username',\n",
    "                    'rahul_count_description', 'rahul_count_screenname', 'rahul_count_url','rahul_count_username', \n",
    "                    'gandhi_count_description','gandhi_count_screenname', 'gandhi_count_url', 'gandhi_count_username',\n",
    "                    'congress_count_description','congress_count_screenname', 'congress_count_url','congress_count_username',\n",
    "                   'भारतीय राष्ट्रीय कांग्रेस_count_description','भारतीय राष्ट्रीय कांग्रेस_count_screenname','भारतीय राष्ट्रीय कांग्रेस_count_url',\n",
    "                    'भारतीय राष्ट्रीय कांग्रेस_count_username','राहुल_count_description', 'राहुल_count_screenname', 'राहुल_count_url',\n",
    "                    'राहुल_count_username', 'गांधी_count_description','गांधी_count_screenname', 'गांधी_count_url', \n",
    "                    'गांधी_count_username','कांग्रेस_count_description','कांग्रेस_count_screenname', 'कांग्रेस_count_url',\n",
    "                    'कांग्रेस_count_username',\n",
    "                   ]\n",
    "inc_keyword_tweet = ['inc_Tweets', 'rahul_Tweets', 'gandhi_Tweets','congress_Tweets', 'भारतीय राष्ट्रीय कांग्रेस_Tweets', 'राहुल_Tweets', 'गांधी_Tweets']\n",
    "\n",
    "\n",
    "\n",
    "aap_keyword_user = ['aap_count_description','aap_count_screenname', 'aap_count_url', 'aap_count_username',\n",
    "                    'kejriwal_count_description', 'kejriwal_count_screenname','kejriwal_count_url', 'kejriwal_count_username',\n",
    "                   'आप_count_description','आप_count_screenname', 'आप_count_url', 'आप_count_username',\n",
    "                    'केजरीवाल_count_description', 'केजरीवाल_count_screenname','केजरीवाल_count_url', 'केजरीवाल_count_username']\n",
    "aap_keyword_tweet = [  'aap_Tweets', 'kejriwal_Tweets','आप_Tweets', 'केजरीवाल_Tweets']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35277799",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keywords = bjp_keyword_user + bjp_keyword_tweet + inc_keyword_user + inc_keyword_tweet + aap_keyword_user + aap_keyword_tweet\n",
    "\n",
    "\n",
    "df_new_short3['BJP_Keyword_Info'] = df_new_short3[bjp_keyword_user].sum(axis = 1)\n",
    "df_new_short3['INC_Keyword_Info'] = df_new_short3[inc_keyword_user].sum(axis = 1)\n",
    "df_new_short3['AAP_Keyword_Info'] = df_new_short3[aap_keyword_user].sum(axis = 1)\n",
    "\n",
    "df_new_short3['BJP_Keyword_Tweet'] = df_new_short3[bjp_keyword_tweet].sum(axis = 1)\n",
    "df_new_short3['INC_Keyword_Tweet'] = df_new_short3[inc_keyword_tweet].sum(axis = 1)\n",
    "df_new_short3['AAP_Keyword_Tweet'] = df_new_short3[aap_keyword_tweet].sum(axis = 1)\n",
    "\n",
    "\n",
    "drop_col = [ 'UserName_lower', 'ScreenName_lower',\n",
    "       'Expanded_URL_lower', 'bjp_count_description', 'bjp_count_screenname',\n",
    "       'bjp_count_url', 'bjp_count_username', 'inc_count_description',\n",
    "       'inc_count_screenname', 'inc_count_url', 'inc_count_username',\n",
    "       'modi_count_description', 'modi_count_screenname', 'modi_count_url',\n",
    "       'modi_count_username', 'rahul_count_description',\n",
    "       'rahul_count_screenname', 'rahul_count_url', 'rahul_count_username',\n",
    "       'gandhi_count_description', 'gandhi_count_screenname',\n",
    "       'gandhi_count_url', 'gandhi_count_username', 'yogi_count_description',\n",
    "       'yogi_count_screenname', 'yogi_count_url', 'yogi_count_username',\n",
    "       'congress_count_description', 'congress_count_screenname',\n",
    "       'congress_count_url', 'congress_count_username',\n",
    "       'aap_count_description', 'aap_count_screenname', 'aap_count_url',\n",
    "       'aap_count_username', 'kejriwal_count_description',\n",
    "       'kejriwal_count_screenname', 'kejriwal_count_url',\n",
    "       'kejriwal_count_username', 'भाजपा_count_description',\n",
    "       'भाजपा_count_screenname', 'भाजपा_count_url', 'भाजपा_count_username',\n",
    "       'भारतीय राष्ट्रीय कांग्रेस_count_description',\n",
    "       'भारतीय राष्ट्रीय कांग्रेस_count_screenname',\n",
    "       'भारतीय राष्ट्रीय कांग्रेस_count_url',\n",
    "       'भारतीय राष्ट्रीय कांग्रेस_count_username', 'मोदी_count_description',\n",
    "       'मोदी_count_screenname', 'मोदी_count_url', 'मोदी_count_username',\n",
    "       'राहुल_count_description', 'राहुल_count_screenname', 'राहुल_count_url',\n",
    "       'राहुल_count_username', 'गांधी_count_description',\n",
    "       'गांधी_count_screenname', 'गांधी_count_url', 'गांधी_count_username',\n",
    "       'योगी_count_description', 'योगी_count_screenname', 'योगी_count_url',\n",
    "       'योगी_count_username', 'कांग्रेस_count_description',\n",
    "       'कांग्रेस_count_screenname', 'कांग्रेस_count_url',\n",
    "       'कांग्रेस_count_username', 'आप_count_description',\n",
    "       'आप_count_screenname', 'आप_count_url', 'आप_count_username',\n",
    "       'केजरीवाल_count_description', 'केजरीवाल_count_screenname',\n",
    "       'केजरीवाल_count_url', 'केजरीवाल_count_username', 'bjp_Tweets',\n",
    "       'inc_Tweets', 'modi_Tweets', 'rahul_Tweets', 'gandhi_Tweets',\n",
    "       'yogi_Tweets', 'congress_Tweets', 'aap_Tweets', 'kejriwal_Tweets',\n",
    "       'भाजपा_Tweets', 'भारतीय राष्ट्रीय कांग्रेस_Tweets', 'मोदी_Tweets',\n",
    "       'राहुल_Tweets', 'गांधी_Tweets', 'योगी_Tweets', 'कांग्रेस_Tweets',\n",
    "       'आप_Tweets', 'केजरीवाल_Tweets', 'UserName', 'ScreenName',\n",
    "       'UserDescription', 'UserURL', 'UserVerified', 'Political', 'Expanded_URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0ffc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short4 = df_new_short3.drop(columns = drop_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a175254",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_new_short4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_political_following = pd.read_csv('Cluster_Following_Data2.csv')\n",
    "df_political_following2 = pd.read_csv('Cluster_Following_Data3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512cc362",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_political_following3 = pd.concat([df_political_following[['User_ID', 'AAP', 'BJP','INC', 'Other', 'Political_Ratio']],df_political_following2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce04e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_political_following3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398fdb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b73605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8fe2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short5 = pd.merge(df_new_short4, df_political_following3, how = 'left')\n",
    "df_new_short5= df_new_short5.drop_duplicates(subset = ['User_ID'])\n",
    "df_new_short5 = df_new_short5.replace(np.nan, 0)\n",
    "df_new_short6 = df_new_short5.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ffabc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba8d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_new_short6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff0a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short5 = df_new_short5.drop_duplicates('User_ID')\n",
    "df_new_short6 = df_new_short6.drop_duplicates('User_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ad5d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_new_short6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2d6a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "political_labels_up = {\n",
    "    'AAP': 2,\n",
    "    'ABVP': 1,\n",
    "    'BJP': 1,\n",
    "    'DMK': 2,\n",
    "    'GOV' : 2,\n",
    "    'INC' : 0,\n",
    "    'No' : 3,\n",
    "    'RJD' : 0,\n",
    "    'SP': 0,\n",
    "    'RSS' : 1,\n",
    "    'SS' : 1,\n",
    "    'GOV':2,\n",
    "    'Undetermined' : -1,\n",
    "    'VHP': 1\n",
    "}\n",
    "\n",
    "\n",
    "df_new_short5['Party_Label'] = df_new_short5['Party'].map(political_labels_up)\n",
    "df_new_short5 = df_new_short5.replace(np.nan, 0)\n",
    "df_new_short6 = df_new_short5.sample(frac = 1)\n",
    "\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\n",
    "df_new_short6= df_new_short6.reset_index(drop = True)\n",
    "df_new_short6 = df_new_short6.loc[df_new_short6.Party_Label != -1].reset_index(drop = True)\n",
    "X = df_new_short6.drop(columns=['Party_Label', 'Party', 'User_ID', 'UserDescription_lower'])\n",
    "\n",
    "y = df_new_short6['Party_Label']\n",
    "\n",
    "\n",
    "model =  RandomForestClassifier()\n",
    "scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=10, scoring=scorer)\n",
    "\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "\n",
    "print(\"Mean cross-validation score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328babce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6.loc[df_new_short6.Party_Label != -1].groupby('Party_Label').count().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d2f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "\n",
    "    model =  RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, preds, average='macro')\n",
    "    precision = precision_score(y_test, preds, average='macro')\n",
    "    recall = recall_score(y_test, preds, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "    print(\"Fold F1 Score:\", f1)\n",
    "    print(\"Fold Precision:\", precision)\n",
    "    print(\"Fold Recall:\", recall)\n",
    "    \n",
    "\n",
    "    all_preds.extend(preds)\n",
    "    all_labels.extend(y_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "mean_precision = np.mean(precision_scores)\n",
    "mean_recall = np.mean(recall_scores)\n",
    "\n",
    "print(\"Mean F1 Score:\", mean_f1)\n",
    "print(\"Mean Precision:\", mean_precision)\n",
    "print(\"Mean Recall:\", mean_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "confusion_matrix = np.array(conf_matrix)\n",
    "\n",
    "true_positives = np.diag(confusion_matrix)\n",
    "false_positives = np.sum(confusion_matrix, axis=0) - true_positives\n",
    "false_negatives = np.sum(confusion_matrix, axis=1) - true_positives\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "for i in range(len(precision)):\n",
    "    print(f\"Class {i}:\")\n",
    "    print(f\"  Precision: {precision[i]}\")\n",
    "    print(f\"  Recall: {recall[i]}\")\n",
    "    print(f\"  F1 Score: {f1_score[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60924fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_predictions(all_labels, all_preds,\n",
    "                              display_labels=['INC', 'BJP', 'Other', 'NP'], cmap=plt.cm.Blues)\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0875b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a3835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "\n",
    "f1_scores = { \n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "precision_scores = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "recall_scores = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "false_negative_rates = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "false_positive_rates = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "accuracies = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X, y), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    lr_model = LogisticRegression()\n",
    "    svm_model = SVC()\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    mlp_model = MLPClassifier()\n",
    "    ada_model = AdaBoostClassifier()\n",
    "    dt_model = DecisionTreeClassifier()\n",
    "    rf_model = RandomForestClassifier()\n",
    "\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "    ada_model.fit(X_train, y_train)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    lr_preds = lr_model.predict(X_test)\n",
    "    svm_preds = svm_model.predict(X_test)\n",
    "    xgb_preds = xgb_model.predict(X_test)\n",
    "    mlp_preds = mlp_model.predict(X_test)\n",
    "    ada_preds = ada_model.predict(X_test)\n",
    "    dt_preds = dt_model.predict(X_test)\n",
    "    rf_preds = rf_model.predict(X_test)\n",
    "\n",
    "    f1_scores[\"Logistic Regression\"].append(f1_score(y_test, lr_preds, average='macro'))\n",
    "    f1_scores[\"SVM\"].append(f1_score(y_test, svm_preds, average='macro'))\n",
    "    f1_scores[\"XGBoost\"].append(f1_score(y_test, xgb_preds, average='macro'))\n",
    "    f1_scores[\"MLP\"].append(f1_score(y_test, mlp_preds, average='macro'))\n",
    "    f1_scores[\"AdaBoost\"].append(f1_score(y_test, ada_preds, average='macro'))\n",
    "    f1_scores[\"Decision Tree\"].append(f1_score(y_test, dt_preds, average='macro'))\n",
    "    f1_scores[\"Random Forests\"].append(f1_score(y_test, rf_preds, average='macro'))\n",
    "\n",
    "    precision_scores[\"Logistic Regression\"].append(precision_score(y_test, lr_preds, average='macro'))\n",
    "    precision_scores[\"SVM\"].append(precision_score(y_test, svm_preds, average='macro'))\n",
    "    precision_scores[\"XGBoost\"].append(precision_score(y_test, xgb_preds, average='macro'))\n",
    "    precision_scores[\"MLP\"].append(precision_score(y_test, mlp_preds, average='macro'))\n",
    "    precision_scores[\"AdaBoost\"].append(precision_score(y_test, ada_preds, average='macro'))\n",
    "    precision_scores[\"Decision Tree\"].append(precision_score(y_test, dt_preds, average='macro'))\n",
    "    precision_scores[\"Random Forests\"].append(precision_score(y_test, rf_preds, average='macro'))\n",
    "\n",
    "    recall_scores[\"Logistic Regression\"].append(recall_score(y_test, lr_preds, average='macro'))\n",
    "    recall_scores[\"SVM\"].append(recall_score(y_test, svm_preds, average='macro'))\n",
    "    recall_scores[\"XGBoost\"].append(recall_score(y_test, xgb_preds, average='macro'))\n",
    "    recall_scores[\"MLP\"].append(recall_score(y_test, mlp_preds, average='macro'))\n",
    "    recall_scores[\"AdaBoost\"].append(recall_score(y_test, ada_preds, average='macro'))\n",
    "    recall_scores[\"Decision Tree\"].append(recall_score(y_test, dt_preds, average='macro'))\n",
    "    recall_scores[\"Random Forests\"].append(recall_score(y_test, rf_preds, average='macro'))\n",
    "\n",
    "    cm_lr = confusion_matrix(y_test, lr_preds)\n",
    "    cm_svm = confusion_matrix(y_test, svm_preds)\n",
    "    cm_xgb = confusion_matrix(y_test, xgb_preds)\n",
    "    cm_mlp = confusion_matrix(y_test, mlp_preds)\n",
    "    cm_ada = confusion_matrix(y_test, ada_preds)\n",
    "    cm_dt = confusion_matrix(y_test, dt_preds)\n",
    "    cm_rf = confusion_matrix(y_test, rf_preds)\n",
    "\n",
    "    tn_lr, fp_lr, fn_lr, tp_lr = cm_lr[0, 0], cm_lr[0, 1], cm_lr[1, 0], cm_lr[1, 1]\n",
    "    tn_svm, fp_svm, fn_svm, tp_svm = cm_svm[0, 0], cm_svm[0, 1], cm_svm[1, 0], cm_svm[1, 1]\n",
    "    tn_xgb, fp_xgb, fn_xgb, tp_xgb = cm_xgb[0, 0], cm_xgb[0, 1], cm_xgb[1, 0], cm_xgb[1, 1]\n",
    "    tn_mlp, fp_mlp, fn_mlp, tp_mlp = cm_mlp[0, 0], cm_mlp[0, 1], cm_mlp[1, 0], cm_mlp[1, 1]\n",
    "    tn_ada, fp_ada, fn_ada, tp_ada = cm_ada[0, 0], cm_ada[0, 1], cm_ada[1, 0], cm_ada[1, 1]\n",
    "    tn_dt, fp_dt, fn_dt, tp_dt = cm_dt[0, 0], cm_dt[0, 1], cm_dt[1, 0], cm_dt[1, 1]\n",
    "    tn_rf, fp_rf, fn_rf, tp_rf = cm_rf[0, 0], cm_rf[0, 1], cm_rf[1, 0], cm_rf[1, 1]\n",
    "\n",
    "    false_negative_rates[\"Logistic Regression\"].append(fn_lr / (fn_lr + tp_lr))\n",
    "    false_negative_rates[\"SVM\"].append(fn_svm / (fn_svm + tp_svm))\n",
    "    false_negative_rates[\"XGBoost\"].append(fn_xgb / (fn_xgb + tp_xgb))\n",
    "    false_negative_rates[\"MLP\"].append(fn_mlp / (fn_mlp + tp_mlp))\n",
    "    false_negative_rates[\"AdaBoost\"].append(fn_ada / (fn_ada + tp_ada))\n",
    "    false_negative_rates[\"Decision Tree\"].append(fn_dt / (fn_dt + tp_dt))\n",
    "    false_negative_rates[\"Random Forests\"].append(fn_rf / (fn_rf + tp_rf))\n",
    "\n",
    "    false_positive_rates[\"Logistic Regression\"].append(fp_lr / (fp_lr + tn_lr))\n",
    "    false_positive_rates[\"SVM\"].append(fp_svm / (fp_svm + tn_svm))\n",
    "    false_positive_rates[\"XGBoost\"].append(fp_xgb / (fp_xgb + tn_xgb))\n",
    "    false_positive_rates[\"MLP\"].append(fp_mlp / (fp_mlp + tn_mlp))\n",
    "    false_positive_rates[\"AdaBoost\"].append(fp_ada / (fp_ada + tn_ada))\n",
    "    false_positive_rates[\"Decision Tree\"].append(fp_dt / (fp_dt + tn_dt))\n",
    "    false_positive_rates[\"Random Forests\"].append(fp_rf / (fp_rf + tn_rf))\n",
    "\n",
    "    accuracies[\"Logistic Regression\"].append(accuracy_score(y_test, lr_preds))\n",
    "    accuracies[\"SVM\"].append(accuracy_score(y_test, svm_preds))\n",
    "    accuracies[\"XGBoost\"].append(accuracy_score(y_test, xgb_preds))\n",
    "    accuracies[\"MLP\"].append(accuracy_score(y_test, mlp_preds))\n",
    "    accuracies[\"AdaBoost\"].append(accuracy_score(y_test, ada_preds))\n",
    "    accuracies[\"Decision Tree\"].append(accuracy_score(y_test, dt_preds))\n",
    "    accuracies[\"Random Forests\"].append(accuracy_score(y_test, rf_preds))\n",
    "\n",
    "    print(\"Fold\", fold)\n",
    "    print(\"Logistic Regression F1 Score:\", f1_scores[\"Logistic Regression\"][-1])\n",
    "    print(\"SVM F1 Score:\", f1_scores[\"SVM\"][-1])\n",
    "    print(\"XGBoost F1 Score:\", f1_scores[\"XGBoost\"][-1])\n",
    "    print(\"MLP F1 Score:\", f1_scores[\"MLP\"][-1])\n",
    "    print(\"AdaBoost F1 Score:\", f1_scores[\"AdaBoost\"][-1])\n",
    "    print(\"Decision Tree F1 Score:\", f1_scores[\"Decision Tree\"][-1])\n",
    "    print(\"Random Forests F1 Score:\", f1_scores[\"Random Forests\"][-1])\n",
    "    print()\n",
    "\n",
    "print(\"Mean F1 Score:\")\n",
    "for model, scores in f1_scores.items():\n",
    "    print(model, np.mean(scores))\n",
    "\n",
    "print(\"\\nMean Precision:\")\n",
    "for model, scores in precision_scores.items():\n",
    "    print(model, np.mean(scores))\n",
    "\n",
    "print(\"\\nMean Recall:\")\n",
    "for model, scores in recall_scores.items():\n",
    "    print(model, np.mean(scores))\n",
    "\n",
    "print(\"\\nMean False Negative Rate:\")\n",
    "for model, rates in false_negative_rates.items():\n",
    "    print(model, np.mean(rates))\n",
    "\n",
    "print(\"\\nMean False Positive Rate:\")\n",
    "for model, rates in false_positive_rates.items():\n",
    "    print(model, np.mean(rates))\n",
    "\n",
    "print(\"\\nMean Accuracy:\")\n",
    "for model, accs in accuracies.items():\n",
    "    print(model, np.mean(accs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b829aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_bio_bag = ['account', 'activist', 'bjp', 'bjym', 'congress', 'district', 'ex',\n",
    "       'former', 'india', 'indian', 'media', 'member', 'national',\n",
    "       'official', 'political', 'president', 'proud', 'secretary',\n",
    "       'social', 'social media', 'state', 'youth', 'जय', 'रत', 'हम']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f893bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6 = df_new_short6.rename(columns = {'AAP': 'AAP_Count', 'BJP': 'BJP_Count', 'INC': 'INC_Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8a24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from stopwords_hindi import hindi_sw\n",
    "sw = hindi_sw.get_hindi_sw()\n",
    "\n",
    "extra_stop_words = ['RT', 'ji', 'amp']\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = text.replace('RT :', '')\n",
    "    stop_words_english = stopwords.words('english')\n",
    "\n",
    "    stop_words_hindi = list(sw)\n",
    "\n",
    "    stop_words_combined = stop_words_english + stop_words_hindi\n",
    "    stop_words = set(stop_words_combined)\n",
    "    stop_words.update(extra_stop_words)\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f442f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_features=25)\n",
    "df_new_short6['UserDescription_lower']= df_new_short6['UserDescription_lower'].apply(remove_stopwords)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_new_short6['UserDescription_lower'])\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174490c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e7f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df['User_ID']= df_new_short6['User_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a9912",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated = pd.merge(df_new_short6, tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b6fb47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68bd299",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated.groupby('Party_Label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated.groupby('Party').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45940db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated.loc[df_new_short6_updated.Party_Label == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5223cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "political_labels_up = {\n",
    "    'AAP': 2,\n",
    "    'ABVP': 1,\n",
    "    'BJP': 1,\n",
    "    'DMK': 2,\n",
    "    'GOV' : 2,\n",
    "    'INC' : 0,\n",
    "    'No' : 3,\n",
    "    'RJD' : 0,\n",
    "    'SP': 0,\n",
    "    'RSS' : 1,\n",
    "    'SS' : 1,\n",
    "    'GOV':2,\n",
    "    'Undetermined' : -1,\n",
    "    'VHP': 1\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "df_new_short6_updated['Party_Label'] = df_new_short6_updated['Party'].map(political_labels_up)\n",
    "df_new_short6_updated = df_new_short6_updated.loc[df_new_short6_updated.Party_Label != -1]\n",
    "df_new_short6_updated = df_new_short6_updated.replace(np.nan, 0)\n",
    "\n",
    "df_new_short6_updated = df_new_short6_updated.reset_index(drop = True)\n",
    "X = df_new_short6_updated.drop(columns=['Party_Label', 'Party', 'User_ID', 'UserDescription_lower'])\n",
    "\n",
    "y = df_new_short6_updated['Party_Label']\n",
    "\n",
    "\n",
    "model =  RandomForestClassifier()\n",
    "scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=10, scoring=scorer)\n",
    "\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "\n",
    "print(\"Mean cross-validation score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a347b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a805a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a050999",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y)\n",
    "feature_importances = model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "feature_importance_df.sort_values('Importance', ascending = False).iloc[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ae54eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f92bb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "\n",
    "    model =  RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, preds, average='macro')\n",
    "    precision = precision_score(y_test, preds, average='macro')\n",
    "    recall = recall_score(y_test, preds, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "    print(\"Fold F1 Score:\", f1)\n",
    "    print(\"Fold Precision:\", precision)\n",
    "    print(\"Fold Recall:\", recall)\n",
    "    \n",
    "\n",
    "    all_preds.extend(preds)\n",
    "    all_labels.extend(y_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "mean_precision = np.mean(precision_scores)\n",
    "mean_recall = np.mean(recall_scores)\n",
    "\n",
    "print(\"Mean F1 Score:\", mean_f1)\n",
    "print(\"Mean Precision:\", mean_precision)\n",
    "print(\"Mean Recall:\", mean_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b2f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "confusion_matrix = np.array(conf_matrix)\n",
    "\n",
    "true_positives = np.diag(confusion_matrix)\n",
    "false_positives = np.sum(confusion_matrix, axis=0) - true_positives\n",
    "false_negatives = np.sum(confusion_matrix, axis=1) - true_positives\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "for i in range(len(precision)):\n",
    "    print(f\"Class {i}:\")\n",
    "    print(f\"  Precision: {precision[i]}\")\n",
    "    print(f\"  Recall: {recall[i]}\")\n",
    "    print(f\"  F1 Score: {f1_score[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb90722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_predictions(all_labels, all_preds,\n",
    "                              display_labels=['INC', 'BJP', 'Other', 'NP'], cmap=plt.cm.Blues)\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d17b851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296209d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14c3e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e0eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073ae4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_political_tweets = pd.read_csv('Non_Political_Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d68640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_political_tweets[['User_ID', 'text']].rename(columns = {'text': 'Tweet_Text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85095854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_tweets(group):\n",
    "    if len(group) >= 20:\n",
    "        return group.sample(20)\n",
    "    else:\n",
    "        return group\n",
    "subset_df = df_all_tweet.groupby('User_ID', group_keys=False).apply(sample_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777d1883",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = pd.concat([subset_df[['User_ID', 'Tweet_Text']],df_non_political_tweets[['User_ID', 'text']].rename(columns = {'text': 'Tweet_Text'})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33078a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def remove_mentions_links(text):\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'https?://\\S+', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "subset_df['clean_tweet_text'] = subset_df['Tweet_Text'].apply(remove_mentions_links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f867a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tweets(group):\n",
    "    return ' '.join(group)\n",
    "\n",
    "merged_tweets_df = subset_df.groupby('User_ID')['clean_tweet_text'].agg(merge_tweets).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa434c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1eff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from stopwords_hindi import hindi_sw\n",
    "sw = hindi_sw.get_hindi_sw()\n",
    "\n",
    "extra_stop_words = ['RT', 'ji', 'amp']\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = text.replace('RT :', '')\n",
    "    stop_words_english = stopwords.words('english')\n",
    "\n",
    "    stop_words_hindi = list(sw)\n",
    "\n",
    "    stop_words_combined = stop_words_english + stop_words_hindi\n",
    "    stop_words = set(stop_words_combined)\n",
    "    stop_words.update(extra_stop_words)\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "\n",
    "merged_tweets_df['clean_tweet_text'] = merged_tweets_df['clean_tweet_text'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eace98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def tweet_to_base_form(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    words = word_tokenize(tweet)\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    base_form_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    base_form_tweet = ' '.join(base_form_words)\n",
    "    \n",
    "    return base_form_tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a1bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_tweets_df['clean_tweet_text'] = merged_tweets_df['clean_tweet_text'].apply(tweet_to_base_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aa57a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_tweets_df['clean_tweet_text'] = merged_tweets_df['clean_tweet_text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b084b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_tweets_df.groupby('User_ID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d6917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "tfidf_vectorizer_tweet = TfidfVectorizer(ngram_range=(1, 3), max_features=25)\n",
    "tfidf_matrix_tweet = tfidf_vectorizer_tweet.fit_transform(merged_tweets_df['clean_tweet_text'])\n",
    "\n",
    "feature_names_tweet = tfidf_vectorizer_tweet.get_feature_names_out()\n",
    "\n",
    "tfidf_df_tweet = pd.DataFrame(tfidf_matrix_tweet.toarray(), columns=feature_names_tweet)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4562fb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a371c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ec5a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df_tweet['User_ID'] = merged_tweets_df['User_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc540eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated2 = pd.merge(df_new_short6_updated, tfidf_df_tweet, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84b3c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated2 = df_new_short6_updated2.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae850443",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56105f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b73074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "political_labels_up = {\n",
    "    'AAP': 2,\n",
    "    'ABVP': 1,\n",
    "    'BJP': 1,\n",
    "    'DMK': 2,\n",
    "    'GOV' : 2,\n",
    "    'INC' : 0,\n",
    "    'No' : 3,\n",
    "    'RJD' : 0,\n",
    "    'SP': 0,\n",
    "    'RSS' : 1,\n",
    "    'SS' : 1,\n",
    "    'GOV':2,\n",
    "    'VHP': 1\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\n",
    "\n",
    "X = df_new_short6_updated2.drop(columns=['Party_Label', 'Party', 'User_ID', 'UserDescription_lower'])\n",
    "\n",
    "y = df_new_short6_updated2['Party_Label']\n",
    "\n",
    "\n",
    "model =  RandomForestClassifier()\n",
    "scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=10, scoring=scorer)\n",
    "\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "\n",
    "print(\"Mean cross-validation score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c84c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfb5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5719914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b14a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated2.loc[df_new_short6_updated2.Party_Label == 1].AveragePosts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c230cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e89c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated2.loc[df_new_short6_updated2.Party_Label == 0].AveragePosts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc38d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated2.loc[df_new_short6_updated2.Party_Label == 2].AveragePosts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c036f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated2.loc[df_new_short6_updated2.Party_Label == 3].AveragePosts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c51709",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817e009b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f524cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "political_labels_up = {\n",
    "    'AAP': 2,\n",
    "    'ABVP': 1,\n",
    "    'BJP': 1,\n",
    "    'DMK': 2,\n",
    "    'GOV' : 2,\n",
    "    'INC' : 0,\n",
    "    'No' : 3,\n",
    "    'RJD' : 0,\n",
    "    'SP': 0,\n",
    "    'RSS' : 1,\n",
    "    'SS' : 1,\n",
    "    'GOV':2,\n",
    "    'Undetermined' : -1,\n",
    "    'VHP': 1\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "df_new_short6_updated2['Party_Label'] = df_new_short6_updated2['Party'].map(political_labels_up)\n",
    "df_new_short6_updated2 = df_new_short6_updated.loc[df_new_short6_updated2.Party_Label != -1]\n",
    "df_new_short6_updated2 = df_new_short6_updated2.replace(np.nan, 0)\n",
    "\n",
    "df_new_short6_updated2 = df_new_short6_updated2.reset_index(drop = True)\n",
    "X = df_new_short6_updated2.drop(columns=['Party_Label', 'Party', 'User_ID', 'UserDescription_lower', 'UserFavoriteCount'])\n",
    "\n",
    "y = df_new_short6_updated2['Party_Label']\n",
    "\n",
    "\n",
    "model =  RandomForestClassifier()\n",
    "scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=10, scoring=scorer)\n",
    "\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "\n",
    "print(\"Mean cross-validation score:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01387841",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e456fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated2.groupby('Party_Label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8d9846",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a51c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a654363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('Political_Alignment_Updated_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68a4b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "\n",
    "    model =  RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, preds, average='macro')\n",
    "    precision = precision_score(y_test, preds, average='macro')\n",
    "    recall = recall_score(y_test, preds, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "    print(\"Fold F1 Score:\", f1)\n",
    "    print(\"Fold Precision:\", precision)\n",
    "    print(\"Fold Recall:\", recall)\n",
    "    \n",
    "\n",
    "    all_preds.extend(preds)\n",
    "    all_labels.extend(y_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "mean_precision = np.mean(precision_scores)\n",
    "mean_recall = np.mean(recall_scores)\n",
    "\n",
    "print(\"Mean F1 Score:\", mean_f1)\n",
    "print(\"Mean Precision:\", mean_precision)\n",
    "print(\"Mean Recall:\", mean_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481f4e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "confusion_matrix = np.array(conf_matrix)\n",
    "\n",
    "true_positives = np.diag(confusion_matrix)\n",
    "false_positives = np.sum(confusion_matrix, axis=0) - true_positives\n",
    "false_negatives = np.sum(confusion_matrix, axis=1) - true_positives\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "for i in range(len(precision)):\n",
    "    print(f\"Class {i}:\")\n",
    "    print(f\"  Precision: {precision[i]}\")\n",
    "    print(f\"  Recall: {recall[i]}\")\n",
    "    print(f\"  F1 Score: {f1_score[i]}\")\n",
    "    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_predictions(all_labels, all_preds,\n",
    "                              display_labels=['INC', 'BJP', 'Other', 'NP'], cmap=plt.cm.Blues)\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001f602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_predictions(all_labels, all_preds,\n",
    "                              display_labels=['INC', 'BJP', 'Other', 'NP'], cmap=plt.cm.Blues)\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8b310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "\n",
    "f1_scores = { \n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "precision_scores = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "recall_scores = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "false_negative_rates = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "false_positive_rates = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "accuracies = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X, y), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    lr_model = LogisticRegression()\n",
    "    svm_model = SVC()\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    mlp_model = MLPClassifier()\n",
    "    ada_model = AdaBoostClassifier()\n",
    "    dt_model = DecisionTreeClassifier()\n",
    "    rf_model = RandomForestClassifier()\n",
    "\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "    ada_model.fit(X_train, y_train)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    lr_preds = lr_model.predict(X_test)\n",
    "    svm_preds = svm_model.predict(X_test)\n",
    "    xgb_preds = xgb_model.predict(X_test)\n",
    "    mlp_preds = mlp_model.predict(X_test)\n",
    "    ada_preds = ada_model.predict(X_test)\n",
    "    dt_preds = dt_model.predict(X_test)\n",
    "    rf_preds = rf_model.predict(X_test)\n",
    "\n",
    "    f1_scores[\"Logistic Regression\"].append(f1_score(y_test, lr_preds, average='macro'))\n",
    "    f1_scores[\"SVM\"].append(f1_score(y_test, svm_preds, average='macro'))\n",
    "    f1_scores[\"XGBoost\"].append(f1_score(y_test, xgb_preds, average='macro'))\n",
    "    f1_scores[\"MLP\"].append(f1_score(y_test, mlp_preds, average='macro'))\n",
    "    f1_scores[\"AdaBoost\"].append(f1_score(y_test, ada_preds, average='macro'))\n",
    "    f1_scores[\"Decision Tree\"].append(f1_score(y_test, dt_preds, average='macro'))\n",
    "    f1_scores[\"Random Forests\"].append(f1_score(y_test, rf_preds, average='macro'))\n",
    "\n",
    "    precision_scores[\"Logistic Regression\"].append(precision_score(y_test, lr_preds, average='macro'))\n",
    "    precision_scores[\"SVM\"].append(precision_score(y_test, svm_preds, average='macro'))\n",
    "    precision_scores[\"XGBoost\"].append(precision_score(y_test, xgb_preds, average='macro'))\n",
    "    precision_scores[\"MLP\"].append(precision_score(y_test, mlp_preds, average='macro'))\n",
    "    precision_scores[\"AdaBoost\"].append(precision_score(y_test, ada_preds, average='macro'))\n",
    "    precision_scores[\"Decision Tree\"].append(precision_score(y_test, dt_preds, average='macro'))\n",
    "    precision_scores[\"Random Forests\"].append(precision_score(y_test, rf_preds, average='macro'))\n",
    "\n",
    "    recall_scores[\"Logistic Regression\"].append(recall_score(y_test, lr_preds, average='macro'))\n",
    "    recall_scores[\"SVM\"].append(recall_score(y_test, svm_preds, average='macro'))\n",
    "    recall_scores[\"XGBoost\"].append(recall_score(y_test, xgb_preds, average='macro'))\n",
    "    recall_scores[\"MLP\"].append(recall_score(y_test, mlp_preds, average='macro'))\n",
    "    recall_scores[\"AdaBoost\"].append(recall_score(y_test, ada_preds, average='macro'))\n",
    "    recall_scores[\"Decision Tree\"].append(recall_score(y_test, dt_preds, average='macro'))\n",
    "    recall_scores[\"Random Forests\"].append(recall_score(y_test, rf_preds, average='macro'))\n",
    "\n",
    "    cm_lr = confusion_matrix(y_test, lr_preds)\n",
    "    cm_svm = confusion_matrix(y_test, svm_preds)\n",
    "    cm_xgb = confusion_matrix(y_test, xgb_preds)\n",
    "    cm_mlp = confusion_matrix(y_test, mlp_preds)\n",
    "    cm_ada = confusion_matrix(y_test, ada_preds)\n",
    "    cm_dt = confusion_matrix(y_test, dt_preds)\n",
    "    cm_rf = confusion_matrix(y_test, rf_preds)\n",
    "\n",
    "    tn_lr, fp_lr, fn_lr, tp_lr = cm_lr[0, 0], cm_lr[0, 1], cm_lr[1, 0], cm_lr[1, 1]\n",
    "    tn_svm, fp_svm, fn_svm, tp_svm = cm_svm[0, 0], cm_svm[0, 1], cm_svm[1, 0], cm_svm[1, 1]\n",
    "    tn_xgb, fp_xgb, fn_xgb, tp_xgb = cm_xgb[0, 0], cm_xgb[0, 1], cm_xgb[1, 0], cm_xgb[1, 1]\n",
    "    tn_mlp, fp_mlp, fn_mlp, tp_mlp = cm_mlp[0, 0], cm_mlp[0, 1], cm_mlp[1, 0], cm_mlp[1, 1]\n",
    "    tn_ada, fp_ada, fn_ada, tp_ada = cm_ada[0, 0], cm_ada[0, 1], cm_ada[1, 0], cm_ada[1, 1]\n",
    "    tn_dt, fp_dt, fn_dt, tp_dt = cm_dt[0, 0], cm_dt[0, 1], cm_dt[1, 0], cm_dt[1, 1]\n",
    "    tn_rf, fp_rf, fn_rf, tp_rf = cm_rf[0, 0], cm_rf[0, 1], cm_rf[1, 0], cm_rf[1, 1]\n",
    "\n",
    "    false_negative_rates[\"Logistic Regression\"].append(fn_lr / (fn_lr + tp_lr))\n",
    "    false_negative_rates[\"SVM\"].append(fn_svm / (fn_svm + tp_svm))\n",
    "    false_negative_rates[\"XGBoost\"].append(fn_xgb / (fn_xgb + tp_xgb))\n",
    "    false_negative_rates[\"MLP\"].append(fn_mlp / (fn_mlp + tp_mlp))\n",
    "    false_negative_rates[\"AdaBoost\"].append(fn_ada / (fn_ada + tp_ada))\n",
    "    false_negative_rates[\"Decision Tree\"].append(fn_dt / (fn_dt + tp_dt))\n",
    "    false_negative_rates[\"Random Forests\"].append(fn_rf / (fn_rf + tp_rf))\n",
    "\n",
    "    false_positive_rates[\"Logistic Regression\"].append(fp_lr / (fp_lr + tn_lr))\n",
    "    false_positive_rates[\"SVM\"].append(fp_svm / (fp_svm + tn_svm))\n",
    "    false_positive_rates[\"XGBoost\"].append(fp_xgb / (fp_xgb + tn_xgb))\n",
    "    false_positive_rates[\"MLP\"].append(fp_mlp / (fp_mlp + tn_mlp))\n",
    "    false_positive_rates[\"AdaBoost\"].append(fp_ada / (fp_ada + tn_ada))\n",
    "    false_positive_rates[\"Decision Tree\"].append(fp_dt / (fp_dt + tn_dt))\n",
    "    false_positive_rates[\"Random Forests\"].append(fp_rf / (fp_rf + tn_rf))\n",
    "\n",
    "    accuracies[\"Logistic Regression\"].append(accuracy_score(y_test, lr_preds))\n",
    "    accuracies[\"SVM\"].append(accuracy_score(y_test, svm_preds))\n",
    "    accuracies[\"XGBoost\"].append(accuracy_score(y_test, xgb_preds))\n",
    "    accuracies[\"MLP\"].append(accuracy_score(y_test, mlp_preds))\n",
    "    accuracies[\"AdaBoost\"].append(accuracy_score(y_test, ada_preds))\n",
    "    accuracies[\"Decision Tree\"].append(accuracy_score(y_test, dt_preds))\n",
    "    accuracies[\"Random Forests\"].append(accuracy_score(y_test, rf_preds))\n",
    "\n",
    "    print(\"Fold\", fold)\n",
    "    print(\"Logistic Regression F1 Score:\", f1_scores[\"Logistic Regression\"][-1])\n",
    "    print(\"SVM F1 Score:\", f1_scores[\"SVM\"][-1])\n",
    "    print(\"XGBoost F1 Score:\", f1_scores[\"XGBoost\"][-1])\n",
    "    print(\"MLP F1 Score:\", f1_scores[\"MLP\"][-1])\n",
    "    print(\"AdaBoost F1 Score:\", f1_scores[\"AdaBoost\"][-1])\n",
    "    print(\"Decision Tree F1 Score:\", f1_scores[\"Decision Tree\"][-1])\n",
    "    print(\"Random Forests F1 Score:\", f1_scores[\"Random Forests\"][-1])\n",
    "    print()\n",
    "\n",
    "print(\"Mean F1 Score:\")\n",
    "for model, scores in f1_scores.items():\n",
    "    print(model, np.mean(scores))\n",
    "\n",
    "print(\"\\nMean Precision:\")\n",
    "for model, scores in precision_scores.items():\n",
    "    print(model, np.mean(scores))\n",
    "\n",
    "print(\"\\nMean Recall:\")\n",
    "for model, scores in recall_scores.items():\n",
    "    print(model, np.mean(scores))\n",
    "\n",
    "print(\"\\nMean False Negative Rate:\")\n",
    "for model, rates in false_negative_rates.items():\n",
    "    print(model, np.mean(rates))\n",
    "\n",
    "print(\"\\nMean False Positive Rate:\")\n",
    "for model, rates in false_positive_rates.items():\n",
    "    print(model, np.mean(rates))\n",
    "\n",
    "print(\"\\nMean Accuracy:\")\n",
    "for model, accs in accuracies.items():\n",
    "    print(model, np.mean(accs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9f6288",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_check = pd.read_csv('test_data_check.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8778e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_check = pd.merge(df_new_short6_updated, test_data_check, on = 'User_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e001b97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b6ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06863d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated2.sort_values('User_ID')[['User_ID', 'Party','BJP_Keyword_Info',\n",
    "       'INC_Keyword_Info', 'AAP_Keyword_Info', 'AAP_Count', 'BJP_Count', 'INC_Count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21061a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a0b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dd0dc90",
   "metadata": {},
   "source": [
    "# All Account Political Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367418e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4f5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e38654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account = df_account[['User_ID', 'UserName', 'ScreenName','UserFollowers', 'UserFriends', 'UserFavoriteCount',\n",
    "       'TotalStatus', 'AccountAgeinDays', 'AveragePosts', 'UserDescription']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8fb048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb517183",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account = pd.concat([df_all_account, df_new_short6_updated2[['User_ID','UserFollowers', 'UserFriends', 'UserFavoriteCount',\n",
    "       'TotalStatus', 'AccountAgeinDays', 'AveragePosts']]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51951c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ae06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account = pd.merge(df_all_account.drop_duplicates('User_ID'), df_new_short3[['User_ID', 'UserName', 'ScreenName', 'UserDescription']], on = 'User_ID',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0463ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d98b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_all_account['UserDescription_x'].fillna(df_all_account['UserDescription_y'], inplace=True)\n",
    "df_all_account['UserName_x'].fillna(df_all_account['UserName_y'], inplace=True)\n",
    "df_all_account['ScreenName_x'].fillna(df_all_account['ScreenName_y'], inplace=True)\n",
    "df_all_account.drop(columns=['UserDescription_y'], inplace=True)\n",
    "df_all_account.drop(columns=['UserName_y'], inplace=True)\n",
    "df_all_account.drop(columns=['ScreenName_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5516e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account = df_all_account.rename(columns = {'UserDescription_x': 'UserDescription','UserName_x': 'UserName',\n",
    "                                                 'ScreenName_x': 'ScreenName'} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe3fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da492f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a566c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_url = pd.read_csv('user_url.csv')\n",
    "df_all_account2 =pd.merge(df_all_account, df_user_url[['User_ID', 'Expanded_URL']], on = 'User_ID', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242cb91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_list = ['bjp', 'inc', 'modi', 'rahul', 'gandhi', 'yogi', 'congress', 'aap', 'kejriwal', \n",
    "              'भाजपा','भारतीय राष्ट्रीय कांग्रेस', 'मोदी' ,'राहुल','गांधी' ,'योगी','कांग्रेस' ,'आप', 'केजरीवाल' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11243d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account2['UserDescription_lower'] = df_all_account2['UserDescription'].str.lower()\n",
    "df_all_account2['UserName_lower'] = df_all_account2['UserName'].str.lower()\n",
    "df_all_account2['ScreenName_lower'] = df_all_account2['ScreenName'].str.lower()\n",
    "df_all_account2['Expanded_URL_lower'] = df_all_account2['Expanded_URL'].str.lower()\n",
    "df_all_account2.UserDescription_lower = df_all_account2.UserDescription_lower.replace(np.nan, 'No Description')\n",
    "for keyword in keywords_list:\n",
    "    df_all_account2[keyword + '_count_description'] = df_all_account2['UserDescription_lower'].str.count(keyword)\n",
    "    df_all_account2[keyword + '_count_screenname'] = df_all_account2['ScreenName_lower'].str.count(keyword)\n",
    "    df_all_account2[keyword + '_count_url'] = df_all_account2['Expanded_URL_lower'].str.count(keyword)\n",
    "    df_all_account2[keyword + '_count_username'] = df_all_account2['UserName_lower'].str.count(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8bb24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account2.UserDescription_lower = df_all_account2.UserDescription_lower.replace(np.nan, 'No Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a954f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyword in keywords_list:\n",
    "    df_all_account2[keyword + '_count_description'] = df_all_account2['UserDescription_lower'].str.count(keyword)\n",
    "    df_all_account2[keyword + '_count_screenname'] = df_all_account2['ScreenName_lower'].str.count(keyword)\n",
    "    df_all_account2[keyword + '_count_url'] = df_all_account2['Expanded_URL_lower'].str.count(keyword)\n",
    "    df_all_account2[keyword + '_count_username'] = df_all_account2['UserName_lower'].str.count(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e6e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_links(text):\n",
    "    return re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "\n",
    "df_all_account2['UserDescription_lower'] = df_all_account2['UserDescription_lower'].apply(remove_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e3563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account3 = pd.merge(df_all_account2,df_user_tweet_keyword, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a952902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account3 = df_all_account3.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4844ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account3['BJP_Keyword_Info'] = df_all_account3[bjp_keyword_user].sum(axis = 1)\n",
    "df_all_account3['INC_Keyword_Info'] = df_all_account3[inc_keyword_user].sum(axis = 1)\n",
    "df_all_account3['AAP_Keyword_Info'] = df_all_account3[aap_keyword_user].sum(axis = 1)\n",
    "\n",
    "df_all_account3['BJP_Keyword_Tweet'] = df_all_account3[bjp_keyword_tweet].sum(axis = 1)\n",
    "df_all_account3['INC_Keyword_Tweet'] = df_all_account3[inc_keyword_tweet].sum(axis = 1)\n",
    "df_all_account3['AAP_Keyword_Tweet'] = df_all_account3[aap_keyword_tweet].sum(axis = 1)\n",
    "\n",
    "\n",
    "drop_col = [ 'UserName_lower', 'ScreenName_lower',\n",
    "       'Expanded_URL_lower', 'bjp_count_description', 'bjp_count_screenname',\n",
    "       'bjp_count_url', 'bjp_count_username', 'inc_count_description',\n",
    "       'inc_count_screenname', 'inc_count_url', 'inc_count_username',\n",
    "       'modi_count_description', 'modi_count_screenname', 'modi_count_url',\n",
    "       'modi_count_username', 'rahul_count_description',\n",
    "       'rahul_count_screenname', 'rahul_count_url', 'rahul_count_username',\n",
    "       'gandhi_count_description', 'gandhi_count_screenname',\n",
    "       'gandhi_count_url', 'gandhi_count_username', 'yogi_count_description',\n",
    "       'yogi_count_screenname', 'yogi_count_url', 'yogi_count_username',\n",
    "       'congress_count_description', 'congress_count_screenname',\n",
    "       'congress_count_url', 'congress_count_username',\n",
    "       'aap_count_description', 'aap_count_screenname', 'aap_count_url',\n",
    "       'aap_count_username', 'kejriwal_count_description',\n",
    "       'kejriwal_count_screenname', 'kejriwal_count_url',\n",
    "       'kejriwal_count_username', 'भाजपा_count_description',\n",
    "       'भाजपा_count_screenname', 'भाजपा_count_url', 'भाजपा_count_username',\n",
    "       'भारतीय राष्ट्रीय कांग्रेस_count_description',\n",
    "       'भारतीय राष्ट्रीय कांग्रेस_count_screenname',\n",
    "       'भारतीय राष्ट्रीय कांग्रेस_count_url',\n",
    "       'भारतीय राष्ट्रीय कांग्रेस_count_username', 'मोदी_count_description',\n",
    "       'मोदी_count_screenname', 'मोदी_count_url', 'मोदी_count_username',\n",
    "       'राहुल_count_description', 'राहुल_count_screenname', 'राहुल_count_url',\n",
    "       'राहुल_count_username', 'गांधी_count_description',\n",
    "       'गांधी_count_screenname', 'गांधी_count_url', 'गांधी_count_username',\n",
    "       'योगी_count_description', 'योगी_count_screenname', 'योगी_count_url',\n",
    "       'योगी_count_username', 'कांग्रेस_count_description',\n",
    "       'कांग्रेस_count_screenname', 'कांग्रेस_count_url',\n",
    "       'कांग्रेस_count_username', 'आप_count_description',\n",
    "       'आप_count_screenname', 'आप_count_url', 'आप_count_username',\n",
    "       'केजरीवाल_count_description', 'केजरीवाल_count_screenname',\n",
    "       'केजरीवाल_count_url', 'केजरीवाल_count_username', 'bjp_Tweets',\n",
    "       'inc_Tweets', 'modi_Tweets', 'rahul_Tweets', 'gandhi_Tweets',\n",
    "       'yogi_Tweets', 'congress_Tweets', 'aap_Tweets', 'kejriwal_Tweets',\n",
    "       'भाजपा_Tweets', 'भारतीय राष्ट्रीय कांग्रेस_Tweets', 'मोदी_Tweets',\n",
    "       'राहुल_Tweets', 'गांधी_Tweets', 'योगी_Tweets', 'कांग्रेस_Tweets',\n",
    "       'आप_Tweets', 'केजरीवाल_Tweets', 'UserName', 'ScreenName',\n",
    "       'UserDescription', 'Expanded_URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c937d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account4 = df_all_account3.drop(columns = drop_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9687fdde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e78373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_political_following_all = pd.read_csv('All_Follower_Political_Friends.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edf8674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f64183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account5 = pd.merge(df_all_account4, df_political_following_all[['User_ID', 'AAP', 'BJP','INC', 'Other', 'Political_Ratio']], how = 'left')\n",
    "df_all_account5= df_all_account5.drop_duplicates(subset = ['User_ID'])\n",
    "df_all_account5 = df_all_account5.replace(np.nan, 0)\n",
    "df_all_account6 = df_all_account5.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c053fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account6 = df_all_account6.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b9956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0929d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e4a612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7caca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = ['account', 'bjp', 'congress', 'delhi', 'endorsement', 'ex',\n",
    "       'former', 'india', 'indian', 'media', 'member', 'national',\n",
    "       'official', 'personal', 'president', 'proud', 'secretary',\n",
    "       'social', 'social media', 'state', 'twitter', 'youth', 'जय', 'यक',\n",
    "       'रत']\n",
    "\n",
    "vectorizer = TfidfVectorizer(vocabulary=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e8d75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d06b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account6['UserDescription_lower']= df_all_account6['UserDescription_lower'].apply(remove_stopwords)\n",
    "tfidf_matrix_all = vectorizer.fit_transform(df_all_account6['UserDescription_lower'])\n",
    "\n",
    "feature_names_all = vectorizer.get_feature_names_out()\n",
    "\n",
    "tfidf_df_all = pd.DataFrame(tfidf_matrix_all.toarray(), columns=feature_names_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2519e713",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c0c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b06251",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4230f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df_all['User_ID']= df_all_account6['User_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d2ffca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfbfec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account6_updated = pd.merge(df_all_account6, tfidf_df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0631c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account6_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f5269",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df_tweet.loc[tfidf_df_tweet.User_ID == 807775550483763200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c133b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account6_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0bb9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account6_updated.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cb1934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ee3c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903a9e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account6_updated2 = pd.merge(df_all_account6_updated, tfidf_df_tweet, on = 'User_ID', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78437c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account6_updated2 = df_all_account6_updated2.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6064ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account6_updated2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a09bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c741b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account6_updated2 = df_all_account6_updated2.rename(columns = {'AAP': 'AAP_Count', 'BJP': 'BJP_Count', 'INC': 'INC_Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723f7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account6_updated2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9098bf6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df_all_account6_updated2[['User_ID', 'UserFollowers', 'UserFriends', 'UserFavoriteCount',\n",
    "       'TotalStatus', 'AccountAgeinDays', 'AveragePosts',\n",
    "       'UserDescription_lower', 'BJP_Keyword_Info', 'INC_Keyword_Info',\n",
    "       'AAP_Keyword_Info', 'BJP_Keyword_Tweet', 'INC_Keyword_Tweet',\n",
    "       'AAP_Keyword_Tweet', 'AAP_Count', 'BJP_Count', 'INC_Count', 'Other',\n",
    "       'Political_Ratio', 'account', 'bjp', 'congress', 'delhi',\n",
    "       'endorsement', 'ex', 'former', 'india_x', 'indian', 'media', 'member',\n",
    "       'national', 'official', 'personal', 'president', 'proud', 'secretary',\n",
    "       'social', 'social media', 'state', 'twitter', 'youth', 'जय_x', 'यक_x',\n",
    "       'रत_x', 'india_y', 'आपक', 'कर', 'जन', 'जय_y', 'जर', 'नम', 'नह', 'पत',\n",
    "       'पर', 'बन', 'भक', 'मन', 'मह', 'यक_y', 'रक', 'रत_y', 'रद', 'रह', 'लग',\n",
    "       'वर', 'सम', 'सर', 'सरक', 'हम']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25374486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b8b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c939f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_political_data = pd.read_csv('Account_Political_Sentiment.csv')\n",
    "df_acc_political_data = df_acc_political_data[['User_ID', 'BJP_Tweets_Percentage',\n",
    "       'INC_Tweets_Percentage', 'Other_Tweets_Percentage','BJP_Negative_Percentage', 'BJP_Neutral_Percentage',\n",
    "       'BJP_Positive_Percentage', 'INC_Negative_Percentage',\n",
    "       'INC_Neutral_Percentage', 'INC_Positive_Percentage',\n",
    "       'Other_Negative_Percentage', 'Other_Neutral_Percentage',\n",
    "       'Other_Positive_Percentage']]\n",
    "\n",
    "df_all_account6_updated3 = pd.merge(df_all_account6_updated2, df_acc_political_data, how = 'left').replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c95ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short3.groupby('Party').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e335f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_updated_pol = pd.read_csv('Political Alignment Inconsistency.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be8965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a642b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp33 = pd.merge(df_new_short3[['User_ID', 'Party']], new_updated_pol, on = 'User_ID', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e331f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_updated_pol[~new_updated_pol.User_ID.isin(df_temp33.User_ID)].rename(columns = {'New_Label': 'Party'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66a6674",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp33['Party'] = df_temp33['Party'].fillna(df_temp33['New_Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc256e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp33 =pd.concat([df_temp33[['User_ID', 'Party']], new_updated_pol[~new_updated_pol.User_ID.isin(df_temp33.User_ID)].rename(columns = {'New_Label': 'Party'})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1aa437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account.groupby('party').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e98b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp33.groupby('Party').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361c31d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_new = pd.merge(df_all_account6_updated3, df_temp33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da2bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a551b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_new.groupby('Party').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd9364f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_new.loc[(train_data_new.Party_Label_2 ==2) & (train_data_new.Pred_Label_new ==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a5f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "train_data_new.loc[train_data_new.User_ID ==719132241482227712,'Party'] = 'BJP'\n",
    "train_data_new.loc[train_data_new.User_ID ==938011561808994304,'Party'] = 'BJP'\n",
    "train_data_new.loc[train_data_new.User_ID ==52687104,'Party'] = 'BJP'\n",
    "train_data_new.loc[train_data_new.User_ID ==1216316271639191552,'Party'] = 'BJP'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "political_labels_up = {\n",
    "    'AAP': 0,\n",
    "    'ABVP': 1,\n",
    "    'BJP': 1,\n",
    "    'DMK': 0,\n",
    "    'GOV' : 4,\n",
    "    'INC' : 0,\n",
    "    'No' : 2,\n",
    "    'RJD' : 1,\n",
    "    'SP': 0,\n",
    "    'RSS' : 1,\n",
    "    'SS' : 1,\n",
    "    'GOV':4,\n",
    "    'Undetermined' : 4,\n",
    "    'VHP': 1,\n",
    "     'Other': 4,\n",
    "    'Other ': 4,\n",
    "    'NonPolitical':2\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "train_data_new['Party_Label'] = train_data_new['Party'].map(political_labels_up)\n",
    "train_data_new = train_data_new.loc[train_data_new.Party_Label != 4]\n",
    "train_data_new = train_data_new.replace(np.nan, 0)\n",
    "\n",
    "train_data_new = train_data_new.reset_index(drop = True)\n",
    "X = train_data_new.drop(columns=['Party_Label', 'Party', 'User_ID', 'UserDescription_lower', 'UserFavoriteCount'])\n",
    "\n",
    "y = train_data_new['Party_Label']\n",
    "\n",
    "\n",
    "model2 =  RandomForestClassifier()\n",
    "scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "scores = cross_val_score(model2, X, y, cv=10, scoring=scorer)\n",
    "\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "\n",
    "print(\"Mean cross-validation score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbfcb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb958f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_new.groupby('Party_Label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae835f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_new.loc[train_data_new.Party_Label ==  2].INC_Tweets_Percentage.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97000619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X_c, y):\n",
    "    X_train, X_test = X_c.iloc[train_index], X_c.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "\n",
    "    model =  RandomForestClassifier(n_estimators= 100, min_samples_split= 5, min_samples_leaf= 1, \n",
    "                                    max_features= 'auto', max_depth= None, bootstrap= False)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    f1 = f1_score(y_test, preds, average='macro')\n",
    "    precision = precision_score(y_test, preds, average='macro')\n",
    "    recall = recall_score(y_test, preds, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "    print(\"Fold F1 Score:\", f1)\n",
    "    print(\"Fold Precision:\", precision)\n",
    "    print(\"Fold Recall:\", recall)\n",
    "\n",
    "\n",
    "    all_preds.extend(preds)\n",
    "    all_labels.extend(y_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "mean_precision = np.mean(precision_scores)\n",
    "mean_recall = np.mean(recall_scores)\n",
    "\n",
    "print(\"Mean F1 Score:\", mean_f1)\n",
    "print(\"Mean Precision:\", mean_precision)\n",
    "print(\"Mean Recall:\", mean_recall)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255520df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm =conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175fe5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e95711",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_new['Pred_Label_new'] = all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce6cb0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117b73fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = np.diag(cm) / np.sum(cm, axis=0)\n",
    "recall = np.diag(cm) / np.sum(cm, axis=1)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "fpr_per_class = np.zeros(cm.shape[0])\n",
    "fnr_per_class = np.zeros(cm.shape[0])\n",
    "\n",
    "for i in range(cm.shape[0]):  # Loop over each class\n",
    "    fp = np.sum(cm[:, i]) - cm[i, i]  # False Positives\n",
    "    tn = np.sum(cm) - np.sum(cm[i, :]) - np.sum(cm[:, i]) + cm[i, i]  # True Negatives\n",
    "    fn = np.sum(cm[i, :]) - cm[i, i]  # False Negatives\n",
    "    tp = cm[i, i]  # True Positives\n",
    "    fpr = fp / (fp + tn) if (fp + tn) != 0 else 0  # False Positive Rate\n",
    "    fnr = fn / (fn + tp) if (fn + tp) != 0 else 0  # False Negative Rate\n",
    "    fpr_per_class[i] = fpr\n",
    "    fnr_per_class[i] = fnr\n",
    "\n",
    "print(\"False Positive Rate per class:\", fpr_per_class)\n",
    "print(\"False Negative Rate per class:\", fnr_per_class)\n",
    "\n",
    "\n",
    "print(\"Precision per class:\", precision)\n",
    "print(\"Recall per class:\", recall)\n",
    "print(\"F1-score per class:\", f1)\n",
    "print(\"False Positive Rate per class:\", fpr_per_class)\n",
    "print(\"False Negative Rate per class:\", fnr_per_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "confusion_matrix = np.array(conf_matrix)\n",
    "\n",
    "true_positives = np.diag(confusion_matrix)\n",
    "false_positives = np.sum(confusion_matrix, axis=0) - true_positives\n",
    "false_negatives = np.sum(confusion_matrix, axis=1) - true_positives\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "for i in range(len(precision)):\n",
    "    print(f\"Class {i}:\")\n",
    "    print(f\"  Precision: {precision[i]}\")\n",
    "    print(f\"  Recall: {recall[i]}\")\n",
    "    print(f\"  F1 Score: {f1_score[i]}\")\n",
    "    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_predictions(all_labels, all_preds,\n",
    "                              display_labels=['INC', 'BJP', 'NP'], cmap=plt.cm.Blues)\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0bfab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70e7ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739d2f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_new.loc[(train_data_new.Party_Label != train_data_new.Pred_Label_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616f7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde74c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb972e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_new['Party_Label_2'] = all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a913f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_new.loc[(train_data_new.Party_Label_2 != train_data_new.Pred_Label_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f7215",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_new.loc[train_data_new.User_ID == 931151634461204482]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d896987d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb23c689",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = RandomForestClassifier(n_estimators= 100, min_samples_split= 5, min_samples_leaf= 1, \n",
    "                                    max_features= 'auto', max_depth= None, bootstrap= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a2880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[['UserFollowers', 'UserFriends', 'TotalStatus', 'AccountAgeinDays',\n",
    "       'AveragePosts', 'BJP_Keyword_Info', 'INC_Keyword_Info',\n",
    "       'AAP_Keyword_Info', 'BJP_Keyword_Tweet', 'INC_Keyword_Tweet',\n",
    "       'AAP_Keyword_Tweet', 'AAP_Count', 'BJP_Count', 'INC_Count', 'Other',\n",
    "       'Political_Ratio', 'account', 'bjp', 'congress', 'delhi', 'endorsement',\n",
    "       'ex', 'former', 'india_x', 'indian', 'media', 'member', 'national',\n",
    "       'official', 'personal', 'president', 'proud', 'secretary', 'social',\n",
    "       'social media', 'state', 'twitter', 'youth', 'जय_x', 'यक_x', 'रत_x',\n",
    "       'india_y', 'आपक', 'कर', 'जन', 'जय_y', 'जर', 'नम', 'नह', 'पत', 'पर',\n",
    "       'बन', 'भक', 'मन', 'मह', 'यक_y', 'रक', 'रत_y', 'रद', 'रह', 'लग', 'वर',\n",
    "       'सम', 'सर', 'सरक', 'हम', 'BJP_Tweets_Percentage',\n",
    "       'INC_Tweets_Percentage', 'Other_Tweets_Percentage',\n",
    "       'BJP_Negative_Percentage', 'BJP_Neutral_Percentage',\n",
    "       'BJP_Positive_Percentage', 'INC_Negative_Percentage',\n",
    "       'INC_Neutral_Percentage', 'INC_Positive_Percentage',\n",
    "       'Other_Negative_Percentage', 'Other_Neutral_Percentage',\n",
    "       'Other_Positive_Percentage']]\n",
    "model2.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c333226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112a8278",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_predict = model2.predict(df_all_account6_updated3[X.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f02e550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fce4e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_predict_df = pd.DataFrame({'User_ID': df_all_account6_updated3.User_ID.tolist(), \n",
    "             'Predicted_PL': pl_predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab970d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_predict_df.groupby('Predicted_PL').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0167a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acece853",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_predict3 = model3.predict(df_all_account6_updated3[X.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f924a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_predict_df3 = pd.DataFrame({'User_ID': df_all_account6_updated3.User_ID.tolist(), \n",
    "             'Predicted_PL': pl_predict3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a28c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_predict_df3.groupby('Predicted_PL').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bfc40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_predict_df3['Party'] = 'BJP'\n",
    "pl_predict_df3.loc[pl_predict_df3.Predicted_PL == 0, 'Party'] = 'INC'\n",
    "pl_predict_df3.loc[pl_predict_df3.Predicted_PL == 2, 'Party'] = 'NP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba302eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_predict_df3.groupby('Party').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae8cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_predict_df3.to_csv('Political_Alignment_Updated_3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52433b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3ec2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f4726",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c = X-X.min()/X.max()-X.min()\n",
    "X_c = X_c.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc8e3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad19a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "\n",
    "f1_scores = { \n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "precision_scores = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "recall_scores = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "false_negative_rates = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "false_positive_rates = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "accuracies = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X_c, y), 1):\n",
    "    X_train, X_test = X_c.iloc[train_index], X_c.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    lr_model = LogisticRegression()\n",
    "    svm_model = SVC()\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    mlp_model = MLPClassifier()\n",
    "    ada_model = AdaBoostClassifier()\n",
    "    dt_model = DecisionTreeClassifier()\n",
    "    rf_model = RandomForestClassifier()\n",
    "\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "    ada_model.fit(X_train, y_train)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    lr_preds = lr_model.predict(X_test)\n",
    "    svm_preds = svm_model.predict(X_test)\n",
    "    xgb_preds = xgb_model.predict(X_test)\n",
    "    mlp_preds = mlp_model.predict(X_test)\n",
    "    ada_preds = ada_model.predict(X_test)\n",
    "    dt_preds = dt_model.predict(X_test)\n",
    "    rf_preds = rf_model.predict(X_test)\n",
    "\n",
    "    f1_scores[\"Logistic Regression\"].append(f1_score(y_test, lr_preds, average='macro'))\n",
    "    f1_scores[\"SVM\"].append(f1_score(y_test, svm_preds, average='macro'))\n",
    "    f1_scores[\"XGBoost\"].append(f1_score(y_test, xgb_preds, average='macro'))\n",
    "    f1_scores[\"MLP\"].append(f1_score(y_test, mlp_preds, average='macro'))\n",
    "    f1_scores[\"AdaBoost\"].append(f1_score(y_test, ada_preds, average='macro'))\n",
    "    f1_scores[\"Decision Tree\"].append(f1_score(y_test, dt_preds, average='macro'))\n",
    "    f1_scores[\"Random Forests\"].append(f1_score(y_test, rf_preds, average='macro'))\n",
    "\n",
    "    precision_scores[\"Logistic Regression\"].append(precision_score(y_test, lr_preds, average='macro'))\n",
    "    precision_scores[\"SVM\"].append(precision_score(y_test, svm_preds, average='macro'))\n",
    "    precision_scores[\"XGBoost\"].append(precision_score(y_test, xgb_preds, average='macro'))\n",
    "    precision_scores[\"MLP\"].append(precision_score(y_test, mlp_preds, average='macro'))\n",
    "    precision_scores[\"AdaBoost\"].append(precision_score(y_test, ada_preds, average='macro'))\n",
    "    precision_scores[\"Decision Tree\"].append(precision_score(y_test, dt_preds, average='macro'))\n",
    "    precision_scores[\"Random Forests\"].append(precision_score(y_test, rf_preds, average='macro'))\n",
    "\n",
    "    recall_scores[\"Logistic Regression\"].append(recall_score(y_test, lr_preds, average='macro'))\n",
    "    recall_scores[\"SVM\"].append(recall_score(y_test, svm_preds, average='macro'))\n",
    "    recall_scores[\"XGBoost\"].append(recall_score(y_test, xgb_preds, average='macro'))\n",
    "    recall_scores[\"MLP\"].append(recall_score(y_test, mlp_preds, average='macro'))\n",
    "    recall_scores[\"AdaBoost\"].append(recall_score(y_test, ada_preds, average='macro'))\n",
    "    recall_scores[\"Decision Tree\"].append(recall_score(y_test, dt_preds, average='macro'))\n",
    "    recall_scores[\"Random Forests\"].append(recall_score(y_test, rf_preds, average='macro'))\n",
    "\n",
    "    cm_lr = confusion_matrix(y_test, lr_preds)\n",
    "    cm_svm = confusion_matrix(y_test, svm_preds)\n",
    "    cm_xgb = confusion_matrix(y_test, xgb_preds)\n",
    "    cm_mlp = confusion_matrix(y_test, mlp_preds)\n",
    "    cm_ada = confusion_matrix(y_test, ada_preds)\n",
    "    cm_dt = confusion_matrix(y_test, dt_preds)\n",
    "    cm_rf = confusion_matrix(y_test, rf_preds)\n",
    "\n",
    "    tn_lr, fp_lr, fn_lr, tp_lr = cm_lr[0, 0], cm_lr[0, 1], cm_lr[1, 0], cm_lr[1, 1]\n",
    "    tn_svm, fp_svm, fn_svm, tp_svm = cm_svm[0, 0], cm_svm[0, 1], cm_svm[1, 0], cm_svm[1, 1]\n",
    "    tn_xgb, fp_xgb, fn_xgb, tp_xgb = cm_xgb[0, 0], cm_xgb[0, 1], cm_xgb[1, 0], cm_xgb[1, 1]\n",
    "    tn_mlp, fp_mlp, fn_mlp, tp_mlp = cm_mlp[0, 0], cm_mlp[0, 1], cm_mlp[1, 0], cm_mlp[1, 1]\n",
    "    tn_ada, fp_ada, fn_ada, tp_ada = cm_ada[0, 0], cm_ada[0, 1], cm_ada[1, 0], cm_ada[1, 1]\n",
    "    tn_dt, fp_dt, fn_dt, tp_dt = cm_dt[0, 0], cm_dt[0, 1], cm_dt[1, 0], cm_dt[1, 1]\n",
    "    tn_rf, fp_rf, fn_rf, tp_rf = cm_rf[0, 0], cm_rf[0, 1], cm_rf[1, 0], cm_rf[1, 1]\n",
    "\n",
    "    false_negative_rates[\"Logistic Regression\"].append(1-recall_score(y_test, lr_preds, average='macro'))\n",
    "    false_negative_rates[\"SVM\"].append(fn_svm / (fn_svm + tp_svm))\n",
    "    false_negative_rates[\"XGBoost\"].append(fn_xgb / (fn_xgb + tp_xgb))\n",
    "    false_negative_rates[\"MLP\"].append(fn_mlp / (fn_mlp + tp_mlp))\n",
    "    false_negative_rates[\"AdaBoost\"].append(fn_ada / (fn_ada + tp_ada))\n",
    "    false_negative_rates[\"Decision Tree\"].append(fn_dt / (fn_dt + tp_dt))\n",
    "    false_negative_rates[\"Random Forests\"].append(fn_rf / (fn_rf + tp_rf))\n",
    "\n",
    "    false_positive_rates[\"Logistic Regression\"].append(fp_lr / (fp_lr + tn_lr))\n",
    "    false_positive_rates[\"SVM\"].append(fp_svm / (fp_svm + tn_svm))\n",
    "    false_positive_rates[\"XGBoost\"].append(fp_xgb / (fp_xgb + tn_xgb))\n",
    "    false_positive_rates[\"MLP\"].append(fp_mlp / (fp_mlp + tn_mlp))\n",
    "    false_positive_rates[\"AdaBoost\"].append(fp_ada / (fp_ada + tn_ada))\n",
    "    false_positive_rates[\"Decision Tree\"].append(fp_dt / (fp_dt + tn_dt))\n",
    "    false_positive_rates[\"Random Forests\"].append(fp_rf / (fp_rf + tn_rf))\n",
    "\n",
    "    accuracies[\"Logistic Regression\"].append(accuracy_score(y_test, lr_preds))\n",
    "    accuracies[\"SVM\"].append(accuracy_score(y_test, svm_preds))\n",
    "    accuracies[\"XGBoost\"].append(accuracy_score(y_test, xgb_preds))\n",
    "    accuracies[\"MLP\"].append(accuracy_score(y_test, mlp_preds))\n",
    "    accuracies[\"AdaBoost\"].append(accuracy_score(y_test, ada_preds))\n",
    "    accuracies[\"Decision Tree\"].append(accuracy_score(y_test, dt_preds))\n",
    "    accuracies[\"Random Forests\"].append(accuracy_score(y_test, rf_preds))\n",
    "\n",
    "\n",
    "print(\"Mean F1 Score:\")\n",
    "for model, scores in f1_scores.items():\n",
    "    print(model, np.mean(scores))\n",
    "\n",
    "print(\"\\nMean Precision:\")\n",
    "for model, scores in precision_scores.items():\n",
    "    print(model, np.mean(scores))\n",
    "\n",
    "print(\"\\nMean Recall:\")\n",
    "for model, scores in recall_scores.items():\n",
    "    print(model, np.mean(scores))\n",
    "\n",
    "print(\"\\nMean False Negative Rate:\")\n",
    "for model, rates in false_negative_rates.items():\n",
    "    print(model, np.mean(rates))\n",
    "\n",
    "print(\"\\nMean False Positive Rate:\")\n",
    "for model, rates in false_positive_rates.items():\n",
    "    print(model, np.mean(rates))\n",
    "\n",
    "print(\"\\nMean Accuracy:\")\n",
    "for model, accs in accuracies.items():\n",
    "    print(model, np.mean(accs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a6c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "100-90.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458adbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    " tn_lr, fp_lr, fn_lr, tp_lr = cm_lr[0, 0], cm_lr[0, 1], cm_lr[1, 0], cm_lr[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69951ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7219084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "\n",
    "f1_scores = { \n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "precision_scores = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "recall_scores = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "false_negative_rates = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "false_positive_rates = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "accuracies = {\n",
    "    \"Logistic Regression\": [],\n",
    "    \"SVM\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"MLP\": [],\n",
    "    \"AdaBoost\": [],\n",
    "    \"Decision Tree\": [],\n",
    "    \"Random Forests\": []\n",
    "}\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X_c, y), 1):\n",
    "    X_train, X_test = X_c.iloc[train_index], X_c.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    lr_model = LogisticRegression()\n",
    "    svm_model = SVC()\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    mlp_model = MLPClassifier()\n",
    "    ada_model = AdaBoostClassifier()\n",
    "    dt_model = DecisionTreeClassifier()\n",
    "    rf_model = RandomForestClassifier()\n",
    "\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "    ada_model.fit(X_train, y_train)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    lr_preds = lr_model.predict(X_test)\n",
    "    svm_preds = svm_model.predict(X_test)\n",
    "    xgb_preds = xgb_model.predict(X_test)\n",
    "    mlp_preds = mlp_model.predict(X_test)\n",
    "    ada_preds = ada_model.predict(X_test)\n",
    "    dt_preds = dt_model.predict(X_test)\n",
    "    rf_preds = rf_model.predict(X_test)\n",
    "\n",
    "    f1_scores[\"Logistic Regression\"].append(f1_score(y_test, lr_preds, average='macro'))\n",
    "    f1_scores[\"SVM\"].append(f1_score(y_test, svm_preds, average='macro'))\n",
    "    f1_scores[\"XGBoost\"].append(f1_score(y_test, xgb_preds, average='macro'))\n",
    "    f1_scores[\"MLP\"].append(f1_score(y_test, mlp_preds, average='macro'))\n",
    "    f1_scores[\"AdaBoost\"].append(f1_score(y_test, ada_preds, average='macro'))\n",
    "    f1_scores[\"Decision Tree\"].append(f1_score(y_test, dt_preds, average='macro'))\n",
    "    f1_scores[\"Random Forests\"].append(f1_score(y_test, rf_preds, average='macro'))\n",
    "\n",
    "    precision_scores[\"Logistic Regression\"].append(precision_score(y_test, lr_preds, average='macro'))\n",
    "    precision_scores[\"SVM\"].append(precision_score(y_test, svm_preds, average='macro'))\n",
    "    precision_scores[\"XGBoost\"].append(precision_score(y_test, xgb_preds, average='macro'))\n",
    "    precision_scores[\"MLP\"].append(precision_score(y_test, mlp_preds, average='macro'))\n",
    "    precision_scores[\"AdaBoost\"].append(precision_score(y_test, ada_preds, average='macro'))\n",
    "    precision_scores[\"Decision Tree\"].append(precision_score(y_test, dt_preds, average='macro'))\n",
    "    precision_scores[\"Random Forests\"].append(precision_score(y_test, rf_preds, average='macro'))\n",
    "\n",
    "    recall_scores[\"Logistic Regression\"].append(recall_score(y_test, lr_preds, average='macro'))\n",
    "    recall_scores[\"SVM\"].append(recall_score(y_test, svm_preds, average='macro'))\n",
    "    recall_scores[\"XGBoost\"].append(recall_score(y_test, xgb_preds, average='macro'))\n",
    "    recall_scores[\"MLP\"].append(recall_score(y_test, mlp_preds, average='macro'))\n",
    "    recall_scores[\"AdaBoost\"].append(recall_score(y_test, ada_preds, average='macro'))\n",
    "    recall_scores[\"Decision Tree\"].append(recall_score(y_test, dt_preds, average='macro'))\n",
    "    recall_scores[\"Random Forests\"].append(recall_score(y_test, rf_preds, average='macro'))\n",
    "\n",
    "    cm_lr = confusion_matrix(y_test, lr_preds)\n",
    "    cm_svm = confusion_matrix(y_test, svm_preds)\n",
    "    cm_xgb = confusion_matrix(y_test, xgb_preds)\n",
    "    cm_mlp = confusion_matrix(y_test, mlp_preds)\n",
    "    cm_ada = confusion_matrix(y_test, ada_preds)\n",
    "    cm_dt = confusion_matrix(y_test, dt_preds)\n",
    "    cm_rf = confusion_matrix(y_test, rf_preds)\n",
    "\n",
    "    fnr_lr = np.diag(cm_lr) / np.sum(cm_lr, axis=1)\n",
    "    fnr_svm = np.diag(cm_svm) / np.sum(cm_svm, axis=1)\n",
    "    fnr_xgb = np.diag(cm_xgb) / np.sum(cm_xgb, axis=1)\n",
    "    fnr_mlp = np.diag(cm_mlp) / np.sum(cm_mlp, axis=1)\n",
    "    fnr_ada = np.diag(cm_ada) / np.sum(cm_ada, axis=1)\n",
    "    fnr_dt = np.diag(cm_dt) / np.sum(cm_dt, axis=1)\n",
    "    fnr_rf = np.diag(cm_rf) / np.sum(cm_rf, axis=1)\n",
    "\n",
    "    false_negative_rates[\"Logistic Regression\"].append(np.mean(fnr_lr))\n",
    "    false_negative_rates[\"SVM\"].append(np.mean(fnr_svm))\n",
    "    false_negative_rates[\"XGBoost\"].append(np.mean(fnr_xgb))\n",
    "    false_negative_rates[\"MLP\"].append(np.mean(fnr_mlp))\n",
    "    false_negative_rates[\"AdaBoost\"].append(np.mean(fnr_ada))\n",
    "    false_negative_rates[\"Decision Tree\"].append(np.mean(fnr_dt))\n",
    "    false_negative_rates[\"Random Forests\"].append(np.mean(fnr_rf))\n",
    "\n",
    "    fpr_lr = (np.sum(cm_lr, axis=0) - np.diag(cm_lr)) / (np.sum(cm_lr) - np.sum(np.diag(cm_lr)))\n",
    "    fpr_svm = (np.sum(cm_svm, axis=0) - np.diag(cm_svm)) / (np.sum(cm_svm) - np.sum(np.diag(cm_svm)))\n",
    "    fpr_xgb = (np.sum(cm_xgb, axis=0) - np.diag(cm_xgb)) / (np.sum(cm_xgb) - np.sum(np.diag(cm_xgb)))\n",
    "    fpr_mlp = (np.sum(cm_mlp, axis=0) - np.diag(cm_mlp)) / (np.sum(cm_mlp) - np.sum(np.diag(cm_mlp)))\n",
    "    fpr_ada = (np.sum(cm_ada, axis=0) - np.diag(cm_ada)) / (np.sum(cm_ada) - np.sum(np.diag(cm_ada)))\n",
    "    fpr_dt = (np.sum(cm_dt, axis=0) - np.diag(cm_dt)) / (np.sum(cm_dt) - np.sum(np.diag(cm_dt)))\n",
    "    fpr_rf = (np.sum(cm_rf, axis=0) - np.diag(cm_rf)) / (np.sum(cm_rf) - np.sum(np.diag(cm_rf)))\n",
    "\n",
    "    false_positive_rates[\"Logistic Regression\"].append(np.mean(fpr_lr))\n",
    "    false_positive_rates[\"SVM\"].append(np.mean(fpr_svm))\n",
    "    false_positive_rates[\"XGBoost\"].append(np.mean(fpr_xgb))\n",
    "    false_positive_rates[\"MLP\"].append(np.mean(fpr_mlp))\n",
    "    false_positive_rates[\"AdaBoost\"].append(np.mean(fpr_ada))\n",
    "    false_positive_rates[\"Decision Tree\"].append(np.mean(fpr_dt))\n",
    "    false_positive_rates[\"Random Forests\"].append(np.mean(fpr_rf))\n",
    "\n",
    "    accuracies[\"Logistic Regression\"].append(accuracy_score(y_test, lr_preds))\n",
    "    accuracies[\"SVM\"].append(accuracy_score(y_test, svm_preds))\n",
    "    accuracies[\"XGBoost\"].append(accuracy_score(y_test, xgb_preds))\n",
    "    accuracies[\"MLP\"].append(accuracy_score(y_test, mlp_preds))\n",
    "    accuracies[\"AdaBoost\"].append(accuracy_score(y_test, ada_preds))\n",
    "    accuracies[\"Decision Tree\"].append(accuracy_score(y_test, dt_preds))\n",
    "    accuracies[\"Random Forests\"].append(accuracy_score(y_test, rf_preds))\n",
    "\n",
    "print(\"Mean F1 Score:\")\n",
    "for model, scores in f1_scores.items():\n",
    "    print(model, np.mean(scores))\n",
    "\n",
    "print(\"\\nMean Precision:\")\n",
    "for model, scores in precision_scores.items():\n",
    "    print(model, np.mean(scores))\n",
    "\n",
    "print(\"\\nMean Recall:\")\n",
    "for model, scores in recall_scores.items():\n",
    "    print(model, np.mean(scores))\n",
    "\n",
    "print(\"\\nMean False Negative Rate:\")\n",
    "for model, rates in false_negative_rates.items():\n",
    "    print(model, np.mean(rates))\n",
    "\n",
    "print(\"\\nMean False Positive Rate:\")\n",
    "for model, rates in false_positive_rates.items():\n",
    "    print(model, np.mean(rates))\n",
    "\n",
    "print(\"\\nMean Accuracy:\")\n",
    "for model, accs in accuracies.items():\n",
    "    print(model, np.mean(accs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(X,y)\n",
    "feature_importances = model2.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "feature_importance_df.sort_values('Importance', ascending = False).iloc[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fc86c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "confusion_matrix = np.array(conf_matrix)\n",
    "\n",
    "true_positives = np.diag(confusion_matrix)\n",
    "false_positives = np.sum(confusion_matrix, axis=0) - true_positives\n",
    "false_negatives = np.sum(confusion_matrix, axis=1) - true_positives\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "for i in range(len(precision)):\n",
    "    print(f\"Class {i}:\")\n",
    "    print(f\"  Precision: {precision[i]}\")\n",
    "    print(f\"  Recall: {recall[i]}\")\n",
    "    print(f\"  F1 Score: {f1_score[i]}\")\n",
    "    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_predictions(all_labels, all_preds,display_labels=['INC', 'BJP', 'Other', 'NP'], cmap=plt.cm.Blues)\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c8ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account6_updated2.loc[df_all_account6_updated2.User_ID == 907498740453335041]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c9ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated2.loc[df_new_short6_updated2.User_ID == 907498740453335041]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f009095d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1557f7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_account6_updated2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5984e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_all_account6_updated2, df_new_short6_updated2[['User_ID', 'Party']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b92ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_political_data = pd.read_csv('Account_Political_Sentiment.csv')\n",
    "df_acc_political_data = df_acc_political_data[['User_ID', 'BJP_Tweets_Percentage',\n",
    "       'INC_Tweets_Percentage', 'Other_Tweets_Percentage','BJP_Negative_Percentage', 'BJP_Neutral_Percentage',\n",
    "       'BJP_Positive_Percentage', 'INC_Negative_Percentage',\n",
    "       'INC_Neutral_Percentage', 'INC_Positive_Percentage',\n",
    "       'Other_Negative_Percentage', 'Other_Neutral_Percentage',\n",
    "       'Other_Positive_Percentage']]\n",
    "\n",
    "df_new_short6_updated3 = pd.merge(df_new_short6_updated2, df_acc_political_data, how = 'left').replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d7466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_political_data = df_acc_political_data[['User_ID', 'BJP_Tweets_Percentage',\n",
    "       'INC_Tweets_Percentage', 'Other_Tweets_Percentage','BJP_Negative_Percentage', 'BJP_Neutral_Percentage',\n",
    "       'BJP_Positive_Percentage', 'INC_Negative_Percentage',\n",
    "       'INC_Neutral_Percentage', 'INC_Positive_Percentage',\n",
    "       'Other_Negative_Percentage', 'Other_Neutral_Percentage',\n",
    "       'Other_Positive_Percentage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41697643",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated3 = pd.merge(df_new_short6_updated2, df_acc_political_data, how = 'left').replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b51855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c688bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated3 = df_new_short6_updated3.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252dec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f94af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "political_labels_up = {\n",
    "    'AAP': 2,\n",
    "    'ABVP': 1,\n",
    "    'BJP': 1,\n",
    "    'DMK': 2,\n",
    "    'GOV' : 2,\n",
    "    'INC' : 0,\n",
    "    'No' : 3,\n",
    "    'RJD' : 0,\n",
    "    'SP': 0,\n",
    "    'RSS' : 1,\n",
    "    'SS' : 1,\n",
    "    'GOV':2,\n",
    "    'Undetermined' : -1,\n",
    "    'VHP': 1\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "df_new_short6_updated3['Party_Label'] = df_new_short6_updated3['Party'].map(political_labels_up)\n",
    "df_new_short6_updated3 = df_new_short6_updated3.loc[df_new_short6_updated3.Party_Label != -1]\n",
    "df_new_short6_updated3 = df_new_short6_updated3.replace(np.nan, 0)\n",
    "\n",
    "df_new_short6_updated3 = df_new_short6_updated3.reset_index(drop = True)\n",
    "X = df_new_short6_updated3.drop(columns=['Party_Label', 'Party', 'User_ID', 'UserDescription_lower', 'UserFavoriteCount'])\n",
    "\n",
    "y = df_new_short6_updated3['Party_Label']\n",
    "\n",
    "\n",
    "model2 =  RandomForestClassifier()\n",
    "scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "scores = cross_val_score(model2, X, y, cv=10, scoring=scorer)\n",
    "\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "\n",
    "print(\"Mean cross-validation score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "\n",
    "    model =  RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    f1 = f1_score(y_test, preds, average='macro')\n",
    "    precision = precision_score(y_test, preds, average='macro')\n",
    "    recall = recall_score(y_test, preds, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "    print(\"Fold F1 Score:\", f1)\n",
    "    print(\"Fold Precision:\", precision)\n",
    "    print(\"Fold Recall:\", recall)\n",
    "\n",
    "\n",
    "    all_preds.extend(preds)\n",
    "    all_labels.extend(y_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "mean_precision = np.mean(precision_scores)\n",
    "mean_recall = np.mean(recall_scores)\n",
    "\n",
    "print(\"Mean F1 Score:\", mean_f1)\n",
    "print(\"Mean Precision:\", mean_precision)\n",
    "print(\"Mean Recall:\", mean_recall)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d5ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "confusion_matrix = np.array(conf_matrix)\n",
    "\n",
    "true_positives = np.diag(confusion_matrix)\n",
    "false_positives = np.sum(confusion_matrix, axis=0) - true_positives\n",
    "false_negatives = np.sum(confusion_matrix, axis=1) - true_positives\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "for i in range(len(precision)):\n",
    "    print(f\"Class {i}:\")\n",
    "    print(f\"  Precision: {precision[i]}\")\n",
    "    print(f\"  Recall: {recall[i]}\")\n",
    "    print(f\"  F1 Score: {f1_score[i]}\")\n",
    "    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_predictions(all_labels, all_preds,\n",
    "                              display_labels=['INC', 'BJP', 'Other', 'NP'], cmap=plt.cm.Blues)\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2983855",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = RandomForestClassifier()\n",
    "model2.fit(X,y)\n",
    "feature_importances = model2.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "feature_importance_df.sort_values('Importance', ascending = False).iloc[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c51e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_short6_updated3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a595f622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989efa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d292a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              