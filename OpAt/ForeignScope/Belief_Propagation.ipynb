{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b02a8-f077-49bf-9d80-c25bbffcab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68f7fe1-341f-4c9f-b2d2-41d8f94bdbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ASG Graph\n",
    "with open(\"graph_IOX.pkl\", \"rb\") as f:\n",
    "    G = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d777af30-8369-455f-9bbc-2d61cdfbeaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''\n",
    "data_file_name = ''\n",
    "df_all_tweet = pd.read_csv(path + data_file_name, dtype = 'str', lineterminator = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa6b423-2e89-4909-acb6-0f17df40f307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba89e619-900c-45e3-92c8-5328ec528ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = ''\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "df_list = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df['source_file'] = os.path.basename(file)\n",
    "    df_list.append(df)\n",
    "\n",
    "df_foreign_sus = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73432951-5a2d-411e-8f69-af188e548897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edf09c1-7cc7-487f-8fab-e4b83ef1020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_tweet['is_Retweet'] = df_all_tweet.apply(\n",
    "    lambda row: 1 if isinstance(row['text'], str) and row['text'].startswith('RT @') else 0,\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c67118-fc0c-4156-9ac8-91f0d099cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_all_tweet.loc[(df_all_tweet.is_Retweet==0) & (df_all_tweet.Text_Lang == 'hi')].User_ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde88bd4-0010-4804-854c-52020cc8464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_india = df_all_tweet.loc[(df_all_tweet.is_Retweet==0) & (df_all_tweet.Text_Lang == 'hi')][['User_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bbf942-add9-46ee-a4c7-38b8507e3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_india = df_india.drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83773b1a-a8d6-48ed-9609-3196b43066eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_india['Country'] = 'India'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d539a3-63d8-43d2-8fcf-2aa3e6dd868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foreign_sus.loc[df_foreign_sus.Country != 'Spanish'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9582940-a520-4964-a7ed-5c10874ca5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foreign_sus['Country'] = df_foreign_sus['source_file'].str.replace('_ID.csv', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef709a8-19cf-4fb8-8b2b-663ae7eeb679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75225ba2-4950-421e-befe-d7f58107d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_india_count = df_all_tweet[(df_all_tweet.is_Retweet==0) & (df_all_tweet.Text_Lang == 'hi')].groupby('User_ID').count().reset_index()[['User_ID', 'Tweet_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d31510-389a-414b-b620-c4ed17edb87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_india = df_india_count.loc[df_india_count.Tweet_ID>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4ab7e-bdf3-4ca2-87eb-d255b63ca19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_india['Country'] = 'India'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dba202-e839-485d-b3ee-9c18837e68eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2983b593-309e-43c1-9746-53bee396d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foreign_sus = pd.concat([df_foreign_sus[['User_ID', 'Country']], df_india[['User_ID', 'Country']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4439d-6635-45d7-b26b-e007d3d58032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foreign_sus.to_csv('Foreign_Supspected.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba762cb4-d853-4d5d-9546-4a7f56bda29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foreign_sus = df_foreign_sus.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59db5d8b-5582-4f88-8da1-d0d6719d9420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foreign_sus.User_ID = df_foreign_sus.User_ID.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294fd879-a493-42af-8803-39534e63105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_copy = G.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf73599-7626-45fc-8440-c5c5319a7966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def run_lbp(G, foreign_accounts, max_iter=10, alpha=0.8):\n",
    "    nodes = list(G.nodes())\n",
    "    belief = {node: 0.0 for node in nodes}\n",
    "    for node in foreign_accounts:\n",
    "        belief[node] = 1.0\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        new_belief = {}\n",
    "        for node in G.nodes():\n",
    "            if node in foreign_accounts:\n",
    "                new_belief[node] = 1.0  \n",
    "            else:\n",
    "                neighbor_beliefs = [belief[neigh] for neigh in G.neighbors(node)]\n",
    "                if neighbor_beliefs:\n",
    "                    mean_belief = np.mean(neighbor_beliefs)\n",
    "                    new_belief[node] = alpha * mean_belief + (1 - alpha) * belief[node]\n",
    "                else:\n",
    "                    new_belief[node] = belief[node]  \n",
    "\n",
    "        belief = new_belief\n",
    "\n",
    "    return belief\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c953243-71f2-4cca-8f28-41d4e6ac8d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def run_lbp_with_edge_potentials(G, foreign_accounts, max_iter=10, alpha=0.8):\n",
    "    nodes = list(G.nodes())\n",
    "    max_weight = max((d.get('weight', 1.0) for u, v, d in G.edges(data=True)), default=1.0)\n",
    "\n",
    "    edge_potentials = {}\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        w = d.get('weight', 1.0)\n",
    "        potential = w / max_weight if max_weight > 0 else 0.0\n",
    "        edge_potentials[(u, v)] = potential\n",
    "        edge_potentials[(v, u)] = potential  \n",
    "\n",
    "    belief = {}\n",
    "    for node in nodes:\n",
    "        if node in foreign_accounts:\n",
    "            belief[node] = 1.0\n",
    "        else:\n",
    "            belief[node] = 0.5\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        new_belief = {}\n",
    "        for node in nodes:\n",
    "            if node in foreign_accounts:\n",
    "                new_belief[node] = 1.0 \n",
    "            else:\n",
    "                neighbor_beliefs = []\n",
    "                total_potential = 0.0\n",
    "                for neighbor in G.neighbors(node):\n",
    "                    potential = edge_potentials.get((node, neighbor), 1.0)\n",
    "                    neighbor_beliefs.append(potential * belief[neighbor])\n",
    "                    total_potential += potential\n",
    "\n",
    "                if total_potential > 0:\n",
    "                    weighted_avg = sum(neighbor_beliefs) / total_potential\n",
    "                    new_belief[node] = alpha * weighted_avg + (1 - alpha) * belief[node]\n",
    "                else:\n",
    "                    new_belief[node] = belief[node]  \n",
    "\n",
    "        belief = new_belief\n",
    "    return belief\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0350d164-3c8d-4c6e-8196-8d9e77e20eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = []\n",
    "\n",
    "for country in df_foreign_sus['Country'].unique():\n",
    "    print(country)\n",
    "    seed_accounts = set(df_foreign_sus[df_foreign_sus['Country'] == country]['User_ID'])\n",
    "    print(len(seed_accounts))\n",
    "    \n",
    "    belief_scores3 = run_lbp_with_edge_potentials(G_copy, seed_accounts)\n",
    "\n",
    "    likely_foreign = sorted(\n",
    "        ((node, score) for node, score in belief_scores3.items() if node not in seed_accounts),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    for node, score in likely_foreign:\n",
    "        results3.append({\n",
    "            'Country': country,\n",
    "            'Inferred_User_ID': node,\n",
    "            'Belief_Score': score\n",
    "        })\n",
    "\n",
    "df_inferred_foreign3 = pd.DataFrame(results3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c6e48e-d4da-4489-8dd0-78239a04e766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40457d8c-6b60-4765-b5b7-b2f4a09920cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inferred_foreign3.loc[df_inferred_foreign3.Belief_Score> 0.6].groupby('Country').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9248499-5d45-44c9-87cc-27f112f8e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    print(len(df_inferred_foreign3.loc[df_inferred_foreign3.Belief_Score> i].Inferred_User_ID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ea1287-90d8-4787-97d2-875d3abd00c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_inferred_foreign3.loc[df_inferred_foreign3.Belief_Score> 0.7].Inferred_User_ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29513d9e-3b7e-4d73-bb63-6192d17bfcc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239c4efe-c65a-4d16-9626-6a3d5fd220fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f591db8b-69cc-44de-b4f5-cea06634d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inferred_foreign.loc[df_inferred_foreign.Belief_Score> 0.5].groupby('Country').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0f0370-e5e2-4f50-b6b9-9b44cd8e86b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9769c5-2626-4cb4-a759-d3d033062dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def run_lbp2(G, foreign_accounts, max_iter=10, alpha=0.8):\n",
    "\n",
    "    nodes = list(G.nodes())\n",
    "    belief = {node: 0.0 for node in nodes}\n",
    "\n",
    "    for node in foreign_accounts:\n",
    "        belief[node] = 1.0\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        new_belief = {}\n",
    "        for node in G.nodes():\n",
    "            if node in foreign_accounts:\n",
    "                new_belief[node] = 1.0 \n",
    "            else:\n",
    "                neighbors = list(G.neighbors(node))\n",
    "                if neighbors:\n",
    "                    total_weight = sum(G[node][neigh].get('weight', 1.0) for neigh in neighbors)\n",
    "                    if total_weight > 0:\n",
    "                        weighted_belief = sum(\n",
    "                            G[node][neigh].get('weight', 1.0) * belief[neigh]\n",
    "                            for neigh in neighbors\n",
    "                        ) / total_weight\n",
    "                        new_belief[node] = alpha * weighted_belief + (1 - alpha) * belief[node]\n",
    "                    else:\n",
    "                        new_belief[node] = belief[node]\n",
    "                else:\n",
    "                    new_belief[node] = belief[node] \n",
    "\n",
    "        belief = new_belief\n",
    "\n",
    "    return belief\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8fe20c-bb8b-428a-bde4-44f39bf0e6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2349bac9-04c5-4333-9b81-8665f430838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_true_lbp(G, foreign_accounts, max_iter=10, damping=0.5, base_strength=1.0):\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    nodes = list(G.nodes())\n",
    "    num_states = 2 \n",
    "    node_potentials = {}\n",
    "    for node in nodes:\n",
    "        if node in foreign_accounts:\n",
    "            node_potentials[node] = np.array([0.001, 0.999])\n",
    "        else:\n",
    "            node_potentials[node] = np.array([0.9, 0.1])\n",
    "    def edge_potential_from_weight(weight, base_strength=1.0):\n",
    "\n",
    "        strength = min(base_strength * (1 + np.log(1 + weight)), 10.0)\n",
    "        high_val = np.exp(strength)\n",
    "        low_val = np.exp(-strength)\n",
    "        if low_val < 1e-10:\n",
    "            low_val = 1e-10\n",
    "            \n",
    "        pot = np.array([\n",
    "            [high_val, low_val],\n",
    "            [low_val, high_val]\n",
    "        ])\n",
    "        return pot / np.sum(pot)  \n",
    "    \n",
    "\n",
    "    messages = defaultdict(lambda: np.ones(num_states) / num_states)\n",
    "    for iteration in range(max_iter):\n",
    "        new_messages = defaultdict(lambda: np.ones(num_states) / num_states)\n",
    "        \n",
    "        for i, j in G.edges():\n",
    "            weight = G[i][j].get('weight', 1.0)\n",
    "            edge_pot = edge_potential_from_weight(weight, base_strength)\n",
    "            msg_i_to_j = np.zeros(num_states)\n",
    "            for state_j in range(num_states):\n",
    "                for state_i in range(num_states):\n",
    "                    value = node_potentials[i][state_i] * edge_pot[state_i, state_j]\n",
    "                    for k in G.neighbors(i):\n",
    "                        if k != j:\n",
    "                            value *= messages[(k, i)][state_i]\n",
    "                    \n",
    "                    msg_i_to_j[state_j] += value\n",
    "            \n",
    "            # Normalize and apply damping\n",
    "            msg_sum = np.sum(msg_i_to_j)\n",
    "            if msg_sum > 0:\n",
    "                msg_i_to_j = msg_i_to_j / msg_sum\n",
    "            else:\n",
    "                msg_i_to_j = np.ones(num_states) / num_states  \n",
    "            \n",
    "            new_messages[(i, j)] = damping * msg_i_to_j + (1 - damping) * messages[(i, j)]\n",
    "            msg_j_to_i = np.zeros(num_states)\n",
    "            for state_i in range(num_states):\n",
    "                for state_j in range(num_states):\n",
    "                    value = node_potentials[j][state_j] * edge_pot[state_i, state_j]\n",
    "                    \n",
    "                    for k in G.neighbors(j):\n",
    "                        if k != i:\n",
    "                            value *= messages[(k, j)][state_j]\n",
    "                    \n",
    "                    msg_j_to_i[state_i] += value\n",
    "            \n",
    "            msg_sum = np.sum(msg_j_to_i)\n",
    "            if msg_sum > 0:\n",
    "                msg_j_to_i = msg_j_to_i / msg_sum\n",
    "            else:\n",
    "                msg_j_to_i = np.ones(num_states) / num_states \n",
    "                \n",
    "            new_messages[(j, i)] = damping * msg_j_to_i + (1 - damping) * messages[(j, i)]\n",
    "        messages = new_messages\n",
    "    \n",
    "    beliefs = {}\n",
    "    for node in nodes:\n",
    "        belief = node_potentials[node].copy()\n",
    "        \n",
    "        for neighbor in G.neighbors(node):\n",
    "            belief *= messages[(neighbor, node)]\n",
    "        \n",
    "        belief_sum = np.sum(belief)\n",
    "        if belief_sum > 0:\n",
    "            belief = belief / belief_sum\n",
    "        else:\n",
    "            belief = np.array([0.5, 0.5]) \n",
    "        beliefs[node] = belief[1] \n",
    "    \n",
    "    return beliefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa56ab-7991-4caa-8a90-77fe2338631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = []\n",
    "\n",
    "for country in df_foreign_sus['Country'].unique():\n",
    "    print(country)\n",
    "    seed_accounts = set(df_foreign_sus[df_foreign_sus['Country'] == country]['User_ID'])\n",
    "    print(len(seed_accounts))\n",
    "    \n",
    "    belief_scores = run_true_lbp(G_copy, seed_accounts)\n",
    "    for node, prob in sorted(belief_scores.items()):\n",
    "        print(f\"Node {node}: {prob:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3070f03-a62d-4077-b632-822a57aed2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for country in df_foreign_sus['Country'].unique():\n",
    "    print(country)\n",
    "    seed_accounts = set(df_foreign_sus[df_foreign_sus['Country'] == country]['User_ID'])\n",
    "    print(len(seed_accounts))\n",
    "    \n",
    "    belief_scores = run_lbp(G_copy, seed_accounts)\n",
    "\n",
    "    likely_foreign = sorted(\n",
    "        ((node, score) for node, score in belief_scores.items() if node not in seed_accounts),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    for node, score in likely_foreign:\n",
    "        results.append({\n",
    "            'Country': country,\n",
    "            'Inferred_User_ID': node,\n",
    "            'Belief_Score': score\n",
    "        })\n",
    "\n",
    "df_inferred_foreign = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7efd8ac-05d8-4751-b30d-2a2a52022773",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = []\n",
    "\n",
    "for country in df_foreign_sus['Country'].unique():\n",
    "    print(country)\n",
    "    seed_accounts = set(df_foreign_sus[df_foreign_sus['Country'] == country]['User_ID'])\n",
    "    print(len(seed_accounts))\n",
    "    \n",
    "    belief_scores2 = run_lbp2(G_copy, seed_accounts)\n",
    "\n",
    "    likely_foreign = sorted(\n",
    "        ((node, score) for node, score in belief_scores2.items() if node not in seed_accounts),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    for node, score in likely_foreign:\n",
    "        results2.append({\n",
    "            'Country': country,\n",
    "            'Inferred_User_ID': node,\n",
    "            'Belief_Score': score\n",
    "        })\n",
    "\n",
    "df_inferred_foreign2 = pd.DataFrame(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ba3ebd-03b3-4971-9563-be613b50d667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d680b-30b1-47e6-be6b-fd15681c729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inferred_foreign2.loc[df_inferred_foreign2.Belief_Score> 0.5].groupby('Country').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ffa61d-6a8d-41f8-8280-e1c6dc870b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inferred_foreign.loc[df_inferred_foreign.Belief_Score> 0.5].groupby('Country').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede4ea2a-52ed-446a-a70f-15d2ff6914b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list = list(G_copy.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647db75e-51a4-4b6a-a634-34314ac40923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6580d3-6e4d-4590-8016-856c5570d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inferred_foreign_valid = df_inferred_foreign.loc[df_inferred_foreign.Belief_Score> 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db14028-f898-4483-9d4e-5167c67eb6b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563e1d20-13f0-4925-a6aa-e05d6e52d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inferred_foreign_valid.groupby('Inferred_User_ID').count().sort_values('Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ca9f25-b94c-46eb-bb97-be2d5cba7485",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_inferred_foreign.loc[df_inferred_foreign.Belief_Score> 0.7].drop_duplicates('Inferred_User_ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a74f92-7674-4645-a3bb-efb4591a4a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_inferred_foreign.loc[df_inferred_foreign.Belief_Score> 0.5].drop_duplicates('Inferred_User_ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37bece2-d6a8-4e01-817a-d4401337ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "from math import exp\n",
    "\n",
    "def normalize_edge_weights(G):\n",
    "    weights = [d.get('weight', 1.0) for _, _, d in G.edges(data=True)]\n",
    "    max_w = max(weights) if weights else 1.0\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        d['norm_weight'] = d.get('weight', 1.0) / max_w\n",
    "\n",
    "def compute_edge_potential(xi, xj, wij, beta):\n",
    "    # Same label: attraction, different label: repulsion\n",
    "    if xi == xj:\n",
    "        return exp(beta * wij)\n",
    "    else:\n",
    "        return exp(-beta * wij)\n",
    "\n",
    "def run_lbp_phi(G, foreign_accounts, beta=1.0, max_iter=10, alpha=0.8):\n",
    "    nodes = list(G.nodes())\n",
    "    normalize_edge_weights(G)\n",
    "\n",
    "    # Initialize beliefs\n",
    "    belief = {}\n",
    "    for node in nodes:\n",
    "        if node in foreign_accounts:\n",
    "            belief[node] = 1.0\n",
    "        else:\n",
    "            belief[node] = 0.5\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        new_belief = {}\n",
    "        for node in nodes:\n",
    "            if node in foreign_accounts:\n",
    "                new_belief[node] = 1.0\n",
    "            else:\n",
    "                num, denom = 0.0, 0.0\n",
    "                for neighbor in G.neighbors(node):\n",
    "                    wij = G[node][neighbor]['norm_weight']\n",
    "                    b_neighbor = belief[neighbor]\n",
    "\n",
    "                    phi_same = compute_edge_potential(1, 1, wij, beta)\n",
    "                    phi_diff = compute_edge_potential(1, 0, wij, beta)\n",
    "\n",
    "                    # Weighted contribution\n",
    "                    num += phi_same * b_neighbor\n",
    "                    denom += phi_same * b_neighbor + phi_diff * (1 - b_neighbor)\n",
    "\n",
    "                if denom > 0:\n",
    "                    prob = num / denom\n",
    "                    new_belief[node] = alpha * prob + (1 - alpha) * belief[node]\n",
    "                else:\n",
    "                    new_belief[node] = belief[node]\n",
    "\n",
    "        belief = new_belief\n",
    "\n",
    "    return belief\n",
    "\n",
    "def evaluate_beta(G, foreign_accounts, beta_values, max_iter=10):\n",
    "    test_size = max(1, int(0.1 * len(foreign_accounts)))\n",
    "    test_nodes = set(random.sample(foreign_accounts, test_size))\n",
    "    train_nodes = set(foreign_accounts) - test_nodes\n",
    "\n",
    "    best_beta, best_loss = None, float('inf')\n",
    "    results = {}\n",
    "\n",
    "    for beta in beta_values:\n",
    "        belief = run_lbp_phi(G, train_nodes, beta=beta, max_iter=max_iter)\n",
    "        loss = sum(1 - belief[n] for n in test_nodes if n in belief)\n",
    "        results[beta] = loss\n",
    "\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_beta = beta\n",
    "\n",
    "    return best_beta, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96947429-431a-4b01-b788-46b41984be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def evaluate_beta(G, foreign_accounts, beta_values, max_iter=10, threshold=0.8):\n",
    "    test_size = max(1, int(0.1 * len(foreign_accounts)))\n",
    "    test_nodes = set(random.sample(foreign_accounts, test_size))\n",
    "    train_nodes = set(foreign_accounts) - test_nodes\n",
    "\n",
    "    best_beta_loss = None\n",
    "    best_beta_ce = None\n",
    "    best_loss = float('inf')\n",
    "    best_ce = float('inf')\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for beta in beta_values:\n",
    "        belief = run_lbp_phi(G, train_nodes, beta=beta, max_iter=max_iter)\n",
    "        loss = sum(1 - belief[n] for n in test_nodes if n in belief)\n",
    "\n",
    "        epsilon = 1e-10  \n",
    "        cross_entropy = -sum(np.log(belief[n] + epsilon) for n in test_nodes if n in belief)\n",
    "        missed_count = sum(1 for n in test_nodes if belief.get(n, 0.0) < threshold)\n",
    "\n",
    "        results[beta] = {\n",
    "            'sum_diff_loss': loss,\n",
    "            'cross_entropy_loss': cross_entropy,\n",
    "            'missed': missed_count,\n",
    "            'total_test': len(test_nodes)\n",
    "        }\n",
    "\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_beta_loss = beta\n",
    "\n",
    "        if cross_entropy < best_ce:\n",
    "            best_ce = cross_entropy\n",
    "            best_beta_ce = beta\n",
    "\n",
    "    return {\n",
    "        'best_beta_sum_diff': best_beta_loss,\n",
    "        'best_sum_diff_loss': best_loss,\n",
    "        'best_beta_cross_entropy': best_beta_ce,\n",
    "        'best_cross_entropy_loss': best_ce,\n",
    "        'results': results\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f606eca-e3e0-4059-bfeb-c297d1135958",
   "metadata": {},
   "outputs": [],
   "source": [
    "beliefs = run_lbp_phi(G, df_foreign_sus.loc[df_foreign_sus.Country == 'India'].User_ID.tolist(), beta=10, max_iter=10, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcdc111-a97e-4122-8a58-32fe923849f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = []\n",
    "for i in df_foreign_sus.Country.unique():\n",
    "    print(i)\n",
    "    beliefs = run_lbp_phi(G, df_foreign_sus.loc[df_foreign_sus.Country == i].User_ID.tolist(), beta=10, max_iter=10, alpha=0.8)\n",
    "    likely_foreign = sorted(((node, score) for node, score in beliefs.items() \n",
    "                             if node not in df_foreign_sus.User_ID.tolist()),key=lambda x: x[1],reverse=True)\n",
    "    \n",
    "    for node, score in likely_foreign:\n",
    "        results2.append({\n",
    "            'Inferred_User_ID': node,'Belief_Score': score, 'Country': i})\n",
    "    \n",
    "df_inferred_foreign2 = pd.DataFrame(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09cfa9d-500d-499e-8c9a-c9b7c9e5f466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foreign_sus.loc[df_foreign_sus.Country == 'Russian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a46dddd-7320-453e-9639-9db6f25d22ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foreign_sus.loc[df_foreign_sus.Country == 'Russian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf85617-9acd-4978-8582-b528ed3cf607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inferred_foreign2.loc[(df_inferred_foreign2.Belief_Score>0.8) & (df_inferred_foreign2.Country=='Russian')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60858ebd-283b-4505-9b2d-adf65714b132",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_inferred_foreign2.loc[df_inferred_foreign2.Belief_Score>0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b096df6f-7e52-4112-8240-d9d8402e1f5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_inferred_foreign2.loc[(df_inferred_foreign2.Belief_Score>0.8) & (df_inferred_foreign2.Country=='Russian')].Inferred_User_ID.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4595450e-0f7e-4087-a672-9d0f66f0f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inferred_foreign2.loc[(df_inferred_foreign2.Belief_Score>0.8) & (df_inferred_foreign2.Country=='Chinese')].Inferred_User_ID.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88e114a-83c1-468c-b21d-4b25e9eba150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inferred_foreign_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fc9a31-97e7-4c8b-adf6-fcb6b8f35dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inferred_foreign2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e698f2-cc9e-4083-80c7-78833c13c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_inferred_foreign2.loc[df_inferred_foreign2.Belief_Score>0.8],df_inferred_foreign_valid]).drop_duplicates(['Inferred_User_ID', 'Country']).to_csv('Suspected_LBP_Foreign.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a0b8e7-6e90-4a72-a13d-e583e30d50b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8966d8-4aa4-4ec1-864e-603bab1c523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_net = df_foreign_sus.loc[df_foreign_sus.User_ID.isin(common_nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0aa35a-9743-4dff-867b-fc86817b31cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_for_net =df_for_net.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2592e4-aca7-4bd9-a6e8-13467fba6ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_beta= evaluate_beta(G, df_for_net.User_ID.tolist(),[0.1, 0.2,0.5, 1, 2, 5,10],threshold=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ba33e9-dbf9-49a0-afae-85c9a9f0ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc59dbfd-1ab3-4b41-bb24-468695a006d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foreign_sus.User_ID.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1185361-a483-4833-af2e-819d5474f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = []\n",
    "likely_foreign = sorted(((node, score) for node, score in beliefs.items() \n",
    "                         if node not in df_foreign_sus.User_ID.tolist()),key=lambda x: x[1],reverse=True)\n",
    "\n",
    "for node, score in likely_foreign:\n",
    "    results2.append({\n",
    "        'Inferred_User_ID': node,'Belief_Score': score})\n",
    "\n",
    "df_inferred_foreign2 = pd.DataFrame(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b442fa-dd78-473a-88d7-07c17e063eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_nodes = set(G.nodes()) \n",
    "df_nodes = set(df_foreign_sus['User_ID'])  \n",
    "common_nodes = graph_nodes.intersection(df_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef52c7d-22f7-4447-bbaa-2243f91ff7d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a7fc8a-eb58-444f-bf3a-80810d8d725f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
