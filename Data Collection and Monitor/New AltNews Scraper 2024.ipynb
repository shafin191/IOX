{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d5bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.font_manager as fm\n",
    "import selenium\n",
    "import getpass\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79e8126",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(selenium.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2563e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ba773",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.altnews.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41126d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cca71bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(driver.current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e5121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(\"window.scrollTo(0, 1080)\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4232822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "a = driver.find_element(by=By.XPATH, value=\"(//div[@class='pbs-col col__xs-1_2'])[position()=574]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c0f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.find_element(By.CSS_SELECTOR, 'a').get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e8a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCROLL_PAUSE_TIME = 10\n",
    "k = 1\n",
    "\n",
    "# Get scroll height\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    k = k + 1\n",
    "    # Scroll down to bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        time.sleep(SCROLL_PAUSE_TIME * 2)\n",
    "    if k == 300:\n",
    "        break\n",
    "    last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc44881",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_link = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a9623",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_link = []\n",
    "for i in range(1,575):\n",
    "    a = driver.find_element(by=By.XPATH, value=\"(//div[@class='pbs-col col__xs-1_2'])[position()=\" + str(i) +\"]\")\n",
    "    all_link.append(a.find_element(By.CSS_SELECTOR, 'a').get_attribute('href'))\n",
    "\n",
    "textfile = open(\"all_link_altNews_2024_updated.txt\", \"w\")\n",
    "for element in all_link:\n",
    "    textfile.write(element + \"\\n\")\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4551a9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_link_altNews_2024_updated.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f635f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_alt=[]\n",
    "for x in lines:\n",
    "    url_alt.append(x.replace(\"\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "proxies = {\n",
    "    'http': 'http://103.230.199.17:10000'\n",
    "}\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "url = \"https://www.altnews.in/haldwani-violence-video-of-scuffle-in-mp-falsely-shared-with-communal-slurs/\"\n",
    "\n",
    "try:\n",
    "    \n",
    "    response = requests.get(url, headers=headers, proxies=proxies)\n",
    "    response.raise_for_status()\n",
    "    print(response.text)  \n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d14c67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(url_alt)):\n",
    "    driver.get(url_alt[i])\n",
    "    with open(\"U:/Twitter Research/Fake News Scraping/AltNews_New_Data/\" + str(i) + \".html\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(driver.page_source)\n",
    "    time.sleep(20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada20a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(url_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d370a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def extract_metadata_from_html(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    link_tag = soup.find('link', rel='canonical')\n",
    "    link = link_tag['href'] if link_tag else \"Link not found\"\n",
    "\n",
    "\n",
    "    title_tag = soup.find('meta', property='og:title')\n",
    "    title = title_tag['content'] if title_tag else \"Title not found\"\n",
    "\n",
    "\n",
    "    published_tag = soup.find('meta', property='article:published_time')\n",
    "    published_date = published_tag['content'] if published_tag else \"Published date not found\"\n",
    "\n",
    "\n",
    "    breadcrumb = soup.find('nav', class_='breadcrumb-nav yoast-breadcrumb')\n",
    "    if breadcrumb:\n",
    "        breadcrumb_links = breadcrumb.find_all('a')\n",
    "        topic = breadcrumb_links[-1].get_text() if breadcrumb_links else \"Topic not found\"\n",
    "    else:\n",
    "        topic = \"Topic not found\"\n",
    "\n",
    "    return link, title, published_date, topic\n",
    "\n",
    "\n",
    "directory_path = 'V:\\\\SBERT All Embedding\\\\AltNews_New_Data\\\\All Webpages\\\\'\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".html\") or filename.endswith(\".htm\"):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            html_content = file.read()\n",
    "\n",
    "        link, title, published_date, topic = extract_metadata_from_html(html_content)\n",
    "\n",
    "        data.append((filename, link, title, published_date, topic))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=['File', 'Link', 'Title', 'Published Date', 'Topic'])\n",
    "print(df)\n",
    "df.to_csv('extracted_metadata_with_topic.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
