{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9af4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import tweepy\n",
    "import pickle\n",
    "import time\n",
    "pd.set_option('display.max_columns', None)  \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11349d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = input(\"Enter the text file name: \")\n",
    "with open(str(file_name)+'.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb98d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_alt=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12483897",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_alt=[]\n",
    "for x in lines:\n",
    "    url_alt.append(x.replace(\"\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc48173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Fact_Checked_Fake_News_Accounts.csv')\n",
    "df = df.drop('Unnamed: 0', axis = 1)\n",
    "old_size = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d464aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_debunked = pd.read_csv('ALT News Debunked Accounts.csv')\n",
    "df_debunked = df_debunked.drop('Unnamed: 0', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824d0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_debunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b504bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded25351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b657e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.DataFrame(df[['Tweet_Topic','Fact_Check_Link']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c115ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.drop_duplicates(keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e92bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic = pd.merge(df_x, pd.DataFrame(news_l.Fact_Check_Link), on='Fact_Check_Link').drop_duplicates('Fact_Check_Link').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3632a50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = pd.merge(df_topic, df_t, on='Fact_Check_Link').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681634bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = pd.read_csv('ALT_NEWS_FACT_CHECK_DATE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37ee529",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = pd.merge(df_n, df_date, on='Fact_Check_Link').reset_index(drop = True).drop(columns = {'Unnamed: 0', 'News_Text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185a1cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = df_n.rename(columns = {'Updated_Text': 'News_Text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9b3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n.to_csv('ALT_NEWS_TEXT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae7dace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98634253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70884a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea3d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_alt = []\n",
    "\n",
    "url_alt.append('https://www.altnews.in/2-year-old-video-of-a-group-of-boys-harassing-a-girl-in-burqa-shared-as-recent/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97284ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(news_l.Fact_Check_Link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41fbc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"Fact_Check_Link\", \"Date\"]\n",
    "df = pd.DataFrame(columns =column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46bb8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_t = [\"Fact_Check_Link\", \"News_Text\"]\n",
    "df_t = pd.DataFrame(columns =column_names_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa66bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e1d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for URL in news_l.Fact_Check_Link:\n",
    "    \n",
    "\n",
    "    try:\n",
    "        page = requests.get(URL)\n",
    "\n",
    "    except:\n",
    "        print(\"Page not found. 404 Error\")\n",
    "        continue\n",
    "\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    \n",
    "    topic = soup.find(id=\"breadcrumbs\")\n",
    "    results = soup.find(id=\"primary\")\n",
    "    news_time = soup.find(class_=\"page-header-inner p-h-i\")\n",
    "    news_text = soup.find(class_=\"content-area c-a\").findAll('p')\n",
    "    job_elements = results.find_all(\"blockquote\", class_=\"twitter-tweet\")\n",
    "    target = soup.find('h4')\n",
    "    for sib in target.find_next_siblings():\n",
    "        if sib.name==\"blockquote\":\n",
    "            a = 1\n",
    "    \n",
    "    for i in range(len(job_elements)):\n",
    "        text = job_elements[i].find(\"p\").text\n",
    "        x = job_elements[i].select(\"p:nth-of-type(2)\")\n",
    "        screen_name = re.findall(r'\\(.*?\\)', str(x))\n",
    "        screen_name = str(screen_name)\n",
    "        screen_name = screen_name.strip(\"[]\")\n",
    "        screen_name = screen_name.replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"\")\n",
    "\n",
    "        try:\n",
    "            link = str(job_elements[i].select(\"a\")[-1])\n",
    "            link = link[link.find(\"=\")+2:link.find(\"?\")]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        df_t.loc[len(df_t.index)] = [URL, str(news_text)]\n",
    "    except:\n",
    "        df_t.loc[len(df_t.index)] = [URL, str('No Text')]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca53f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.loc[df_t.News_Text == 'No Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"This is a sentence. <once a day) [twice a day>\"\n",
    "x = re.sub(\"\\<.*?>|\",\"\",z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9173a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_t.iterrows():\n",
    "    z = df_t.News_Text[index]\n",
    "    df_t.at[index,'Updated_Text'] = re.sub(\"\\<.*?>|\",\"\",z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafa8018",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796f4174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc044c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for URL in url_alt:#news_l.Fact_Check_Link:\n",
    "    \n",
    "\n",
    "    try:\n",
    "        page = requests.get(URL)\n",
    "\n",
    "    except:\n",
    "        print(\"Page not found. 404 Error\")\n",
    "        continue\n",
    "\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    \n",
    "    topic = soup.find(id=\"breadcrumbs\")\n",
    "    results = soup.find(id=\"primary\")\n",
    "    news_time = soup.find(class_=\"page-header-inner p-h-i\")\n",
    "    news_text = soup.find(\"content-area c-a\")\n",
    "    job_elements = results.find_all(\"blockquote\", class_=\"twitter-tweet\")\n",
    "    target = soup.find('h4')\n",
    "    for sib in target.find_next_siblings():\n",
    "        if sib.name==\"blockquote\":\n",
    "            a = 1\n",
    "    \n",
    "    for i in range(len(job_elements)):\n",
    "        text = job_elements[i].find(\"p\").text\n",
    "        x = job_elements[i].select(\"p:nth-of-type(2)\")\n",
    "        screen_name = re.findall(r'\\(.*?\\)', str(x))\n",
    "        screen_name = str(screen_name)\n",
    "        screen_name = screen_name.strip(\"[]\")\n",
    "        screen_name = screen_name.replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"\")\n",
    "\n",
    "        try:\n",
    "            link = str(job_elements[i].select(\"a\")[-1])\n",
    "            link = link[link.find(\"=\")+2:link.find(\"?\")]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        df.loc[len(df.index)] = [URL, str(news_time.time).split('=')[2][1:11]]\n",
    "    except:\n",
    "        df.loc[len(df.index)] = [URL, str('No Date')]\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b357f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.Date == 'No Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(news_time.time).split('=')[2][1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef78d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.Date == 'No Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c8880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ALT_NEWS_FACT_CHECK_DATE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ff6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[450].Date = '2020-04-27'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f1b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(news_time).split('=')[2][1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b6e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Final_Fake_Accounts.csv')\n",
    "df1 = df1.rename(columns = {'UserID': 'User_ID'})\n",
    "df1 = df1.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1f876",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_l = pd.DataFrame(df1.groupby('Fact_Check_Link').count().reset_index()['Fact_Check_Link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fbf468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac9f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c7041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date']= df['Date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013362b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['axes.linewidth'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9086eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,8))\n",
    "ax = fig.gca()\n",
    "plt.hist(df.Date, bins = 30, color = 'slategrey', )\n",
    "plt.xlabel('Date', fontsize=16)\n",
    "plt.ylabel('Count', fontsize=16)\n",
    "plt.savefig(\"Fact_Check_News_Collection_Date_Histogram.png\", bbox_inches=\"tight\", dpi=600, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0eb2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6102c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.distplot( a=df.Date, hist=True, kde=False, rug=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119d5ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5728f26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5664d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.altnews.in/video-of-mainpuri-girl-arrested-with-315-country-made-gun-viral-with-false-muslim-angle/'\n",
    "try:\n",
    "    page = requests.get(URL)\n",
    "    print(page)\n",
    "\n",
    "except:\n",
    "    print(\"Page not found. 404 Error\")\n",
    "    \n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a132453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Fact_Checked_Fake_News_Accounts.csv')\n",
    "df = df.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4032b87a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9071da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = soup.find(id=\"breadcrumbs\")\n",
    "results = soup.find(id=\"primary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f100b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8062a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff1fb83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1625487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_elements = results.find_all(\"blockquote\", class_=\"twitter-tweet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62466ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(job_elements)):\n",
    "    text = job_elements[i].find(\"p\").text\n",
    "    x = job_elements[i].select(\"p:nth-of-type(2)\")\n",
    "    screen_name = re.findall(r'\\(.*?\\)', str(x))\n",
    "    screen_name = str(screen_name)\n",
    "    print(str(x))\n",
    "    screen_name = screen_name.strip(\"[]\")\n",
    "    screen_name = screen_name.replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"\")\n",
    "    \n",
    "    link = str(job_elements[i].select(\"a\")[-1])\n",
    "    link = link[link.find(\"=\")+2:link.find(\"?\")]\n",
    "    \n",
    "    print(text)\n",
    "    print(str(link).split('/')[3])\n",
    "    print(link)\n",
    "    print(str(link).split('/')[-1])\n",
    "    print(topic.text.split(' ')[3])\n",
    "    print(URL)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ef5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_elements = results.find_all('twitter-tweet',class_=\"content-area\")\n",
    "for i in range(len(job_elements)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efee8b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = BeautifulSoup(request.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a073ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_elements = results.find_all(\"blockquote\", class_=\"twitter-tweet\")\n",
    "job_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c7a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.altnews.in/tripura-old-communal-rally-video-viral-as-recent-incident/'\n",
    "try:\n",
    "    page = requests.get(URL)\n",
    "    print(page)\n",
    "\n",
    "except:\n",
    "    print(\"Page not found. 404 Error\")\n",
    "    \n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffd9a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "heading_tags = [\"h4\"]\n",
    "for tags in Soup.find_all(heading_tags):\n",
    "    print(tags.name + ' -> ' + tags.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45746eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = soup.find('h4')\n",
    "for sib in target.find_next_siblings():\n",
    "    if sib.name==\"blockquote\":\n",
    "        print(sib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40b2a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    "url_link = 'https://www.altnews.in/tripura-old-communal-rally-video-viral-as-recent-incident/'\n",
    "request = requests.get(url_link)\n",
    " \n",
    "Soup = BeautifulSoup(request.text, 'lxml')\n",
    " \n",
    "heading_tags = [\"h4\"]\n",
    "for tags in Soup.find_all(heading_tags):\n",
    "    print(tags.name + ' -> ' + tags.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a171c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty = df[0:0]\n",
    "for URL in url_alt:\n",
    "    \n",
    "    try:\n",
    "        page = requests.get(URL)\n",
    "\n",
    "    except:\n",
    "        print(\"Page not found. 404 Error\")\n",
    "        break\n",
    "\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    \n",
    "    topic = soup.find(id=\"breadcrumbs\")\n",
    "    results = soup.find(id=\"primary\")\n",
    "    \n",
    "    job_elements = []\n",
    "    target = soup.find('h4')\n",
    "    for sib in target.find_next_siblings():\n",
    "        if sib.name==\"blockquote\":\n",
    "            job_elements.append(sib)\n",
    "    \n",
    "    for i in range(len(job_elements)):\n",
    "        text = job_elements[i].find(\"p\").text\n",
    "        x = job_elements[i].select(\"p:nth-of-type(2)\")\n",
    "        screen_name = re.findall(r'\\(.*?\\)', str(x))\n",
    "        screen_name = str(screen_name)\n",
    "        screen_name = screen_name.strip(\"[]\")\n",
    "        screen_name = screen_name.replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"\")\n",
    "\n",
    "        try:\n",
    "            link = str(job_elements[i].select(\"a\")[-1])\n",
    "            link = link[link.find(\"=\")+2:link.find(\"?\")]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        df_empty.loc[len(df_empty.index)] = ['@' + str(link).split('/')[3], text, link, str(str(link).split('/')[-1]), topic.text.split(' ')[3], URL]\n",
    "    df_empty.to_csv('Fact_Checked_Fake_News_Accounts_Debunk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7d95fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_empty = df_empty.rename(columns={\"Screen_Name\": \"ScreenName\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Screen_Name\": \"ScreenName\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec45e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.merge(df,df_empty, indicator=True, how='outer').query('_merge==\"left_only\"').drop('_merge', axis=1)\n",
    "df_fake = df_fake.drop_duplicates(subset='Tweet_ID', keep=\"first\")\n",
    "df_fake = df_fake.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a06697",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecf78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['ScreenName'] ='@' + df_all['ScreenName'].astype(str)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake['ScreenName'] = df_fake['ScreenName'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6accb316",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['ScreenName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_fake = pd.merge(df_all, df_fake, on='ScreenName', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83772ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_fake = df_all_fake.dropna(subset=['Fact_Check_Link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681185d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_fake = df_all_fake.drop('Unnamed: 0', axis = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f815d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_fake.to_csv('Final_Fake_Accounts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ca01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_fake.groupby('Tweet_Topic').count().to_csv('Fake Tweet Types.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80993eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df_all_fake.groupby('ScreenName').count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b209a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count.loc[df_count.UserID>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c5c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_fake['ScreenName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad45cae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = df_fake.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbea4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake.to_csv('ALT News Fake Accounts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc4ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty.to_csv('ALT News Debunked Accounts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884fa426",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('Fake_Accounts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca19ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake_all = pd.merge(df_all,df_fake,on = 'ScreenName', indicator=True, how='outer').query('_merge==\"left_only\"').drop('_merge', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc43e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake=df_fake.rename(columns={\"Screen_Name\": \"ScreenName\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b8a640",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffe3beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_fake_sc = df_all_fake['UserID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08511cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_fake_sc = df_all_fake_sc.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f8525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key1 = \"\"\n",
    "key2 = \"\"\n",
    "key3 = \"\"\n",
    "key4 = \"\"\n",
    "\n",
    "\n",
    "auth = tweepy.OAuthHandler(key1, key2)\n",
    "auth.set_access_token(key3, key4)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d34a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cdca46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23561bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b271a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "it = 0\n",
    "old_length = 0\n",
    "new_length =0\n",
    "consumer_key = key1\n",
    "consumer_secret = key2\n",
    "access_key = key3\n",
    "access_secret = key4\n",
    "err = []\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "for i in userid[48:]:\n",
    "    alltweets = []\n",
    "    try:\n",
    "        new_tweets = api.user_timeline(user_id = i,count=200, tweet_mode=\"extended\")\n",
    "    except:\n",
    "        print('Error: '+ str(i))\n",
    "        err.append(i)\n",
    "        continue\n",
    "\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "    oldest = alltweets[-1].id - 1\n",
    "\n",
    "    while len(new_tweets) > 0:\n",
    "\n",
    "        new_tweets = api.user_timeline(user_id = i,count=200,max_id=oldest, tweet_mode=\"extended\")\n",
    "\n",
    "        alltweets.extend(new_tweets)\n",
    "\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        with open('U:/Twitter Research/Fake News Scraping/Fake Accounts/Fake_News_'+str(i) +'.data', 'wb') as filehandle:\n",
    "            pickle.dump(alltweets, filehandle)\n",
    "\n",
    "    new_length = len(alltweets)\n",
    "    print(f\"...{new_length} tweets downloaded so far for {i}\")\n",
    "    print(str(it))\n",
    "    time.sleep(15*30)\n",
    "    it+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18198782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcda611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578f5e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "userid[47:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b20a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "err1 = err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d27ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "err2 = err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041cc688",
   "metadata": {},
   "outputs": [],
   "source": [
    "err1 = err1.append(err2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ff505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_fake = df_all_fake.drop([1])\n",
    "df_all_fake = df_all_fake.reset_index(drop= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70324f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_userid = userid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0333949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "userid = userid[174:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3490178",
   "metadata": {},
   "outputs": [],
   "source": [
    "userid[435]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dffa80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae6dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7583254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_fake.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55953ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e50e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    