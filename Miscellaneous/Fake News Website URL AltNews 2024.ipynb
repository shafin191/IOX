{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbad372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b2cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e52c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Check_Link.csv', lineterminator='\\n', dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55adabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd56c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('Check_Link.csv', lineterminator='\\n', dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c64de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby('Cluster_ID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7831cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Link'].apply(lambda x: len(x) > 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7cd821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_domain(link):\n",
    "    if isinstance(link, str):\n",
    "        try:\n",
    "            link = ast.literal_eval(link) \n",
    "        except (ValueError, SyntaxError):\n",
    "            return None\n",
    "    \n",
    "    if isinstance(link, list) and len(link) > 0:\n",
    "        link = link[0]  \n",
    "    \n",
    "    if isinstance(link, dict):\n",
    "        expanded_url = link.get('expanded_url', '')\n",
    "        match = re.search(r'https?://([^/]+)', expanded_url)\n",
    "        return match.group(1) if match else None\n",
    "    return None\n",
    "\n",
    "df['domain'] = df['Link'].apply(extract_domain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a948d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a66f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da2340",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[2].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94150625",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,3200):\n",
    "    if data[i].id == 1621017001375453186:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_Tweet = df_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cc8ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen = df_URL_Tweet.loc[(df_URL_Tweet.domain != 'twitter.com') &\n",
    "           (df_URL_Tweet.domain !='youtu.be') &\n",
    "          (df_URL_Tweet.domain != 'm.facebook.com') &\n",
    "          (df_URL_Tweet.domain != 'facebook.com')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e0c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain_tld(url):\n",
    "    return '.'.join(url.split('.')[-2:])\n",
    "\n",
    "df_URL_gen['Tweet_Link_2'] = df_URL_gen['domain'].apply(get_domain_tld)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b76942",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_URL_gen.loc[df_URL_gen.Tweet_Link_2 == 'opindia.com'].groupby('Cluster_ID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb77ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_URL.Retweet_Text.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00b080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain_tld(url):\n",
    "    return '.'.join(url.split('.')[-2:])\n",
    "\n",
    "df_URL_gen['Tweet_Link_2'] = df_URL_gen['Tweet_Link'].apply(get_domain_tld)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32617379",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen['Tweet_Link_2'] = df_URL_gen['Tweet_Link_2'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa9a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/disk/mnemo/users/randomuser/USA Influence Opearations/Biased Website Links/biased_unreliable_websites.txt', 'r') as file:\n",
    "    domain_list = [line.strip() for line in file]\n",
    "\n",
    "def match_domain(expanded_url):\n",
    "    if expanded_url: \n",
    "        for domain in domain_list:\n",
    "            if domain == expanded_url:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567b6b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen['domain_match_Biased_Websites'] = df_URL_gen['Tweet_Link_2'].apply(match_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9b8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen.loc[df_URL_gen.domain_match_Biased_Websites == True].groupby('Cluster_ID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dccb43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen.loc[df_URL_gen.domain_match_Biased_Websites == True].groupby('domain').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e196c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv(path):\n",
    "    dataframes1 = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(path, filename)\n",
    "            try:\n",
    "                if os.path.getsize(file_path) > 0:\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    dataframes1.append(df)\n",
    "                else:\n",
    "                    print(f\"Skipping empty file: {filename}\")\n",
    "            except pd.errors.EmptyDataError:\n",
    "                print(f\"EmptyDataError: Skipping file {filename} as it contains no data.\")\n",
    "            except pd.errors.ParserError:\n",
    "                print(f\"ParserError: Skipping file {filename} due to parsing issues.\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while reading {filename}: {e}\")\n",
    "                \n",
    "    if dataframes1:\n",
    "        final_dataframe1 = pd.concat(dataframes1, ignore_index=True)\n",
    "        print(\"All files have been concatenated successfully.\")\n",
    "    else:\n",
    "        print(\"No valid CSV files to concatenate.\")\n",
    "    \n",
    "    return final_dataframe1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1f632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(domain_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f4e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake_usa_website = merge_csv(\"/disk/mnemo/users/randomuser/USA Influence Opearations/Fake Website Scrape/Website Dataset/List of political disinformation website campaigns in the United States - Wikipedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cc13d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(domain_list).intersection(df_fake_usa_website.Domain.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6744b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_fake_usa_website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ff1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake_usa_website['Domain'] = df_fake_usa_website['Domain'].str.lower()\n",
    "df_fake_usa_website['Domain'] = df_fake_usa_website['Domain'].str.replace(r'[.]', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ed505",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_list2 = df_fake_usa_website.Domain.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e877f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_subdomain(domain):\n",
    "    parts = domain.split('.')\n",
    "    if len(parts) > 2:\n",
    "        return '.'.join(parts[-2:])\n",
    "    return domain\n",
    "\n",
    "df_URL_gen['Tweet_Link_2'] = df_URL_gen['Tweet_Link_2'].apply(remove_subdomain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d7c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen['domain_match_fake_USA_website'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0461c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_domain2(expanded_url):\n",
    "    if isinstance(expanded_url, str): \n",
    "        for domain in domain_list2:\n",
    "            \n",
    "            if isinstance(domain, str) and domain == expanded_url:  \n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e714d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen['domain_match_fake_USA_website'] = df_URL_gen['Tweet_Link_2'].apply(match_domain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6c4a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen.loc[df_URL_gen.domain_match_fake_USA_website == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9185ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake_usa_international = merge_csv(\"/disk/mnemo/users/randomuser/USA Influence Opearations/Fake Website Scrape/Website Dataset/List of political disinformation website campaigns-Wikipedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27273a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_domain3(expanded_url):\n",
    "    if isinstance(expanded_url, str):  \n",
    "        for domain in domain_list3: \n",
    "            if isinstance(domain, str) and domain == expanded_url:  \n",
    "                return True\n",
    "    return False\n",
    "\n",
    "df_fake_usa_international['Domain'] = df_fake_usa_international['Domain'].str.lower()\n",
    "df_fake_usa_international['Domain'] = df_fake_usa_international['Domain'].str.replace(r'[.]', '.')\n",
    "domain_list3 = df_fake_usa_international.Domain.to_list()\n",
    "df_URL_gen['domain_match_fake_International_website'] = False\n",
    "df_URL_gen['domain_match_fake_International_website'] = df_URL_gen['Tweet_Link_2'].apply(match_domain3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b144a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen.loc[df_URL_gen.domain_match_fake_International_website == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f70c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92e218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_domain4(expanded_url):\n",
    "    if isinstance(expanded_url, str): \n",
    "        for domain in domain_list4:\n",
    "            \n",
    "            if isinstance(domain, str) and domain == expanded_url:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "df_fake_india = pd.read_csv(\"/disk/mnemo/users/randomuser/USA Influence Opearations/Fake Website Scrape/Website Dataset/List of political disinformation website campaigns-Wikipedia/India.csv\")\n",
    "\n",
    "df_fake_india['Domain'] = df_fake_india['Domain'].str.lower()\n",
    "df_fake_india['Domain'] = df_fake_india['Domain'].str.replace(r'[.]', '.')\n",
    "domain_list4 = df_fake_india.Domain.to_list()\n",
    "df_URL_gen['domain_match_fake_india_website'] = False\n",
    "df_URL_gen['domain_match_fake_india_website'] = df_URL_gen['Tweet_Link_2'].apply(match_domain4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e479ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen.loc[df_URL_gen.domain_match_fake_india_website == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9536a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_fake_general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759462aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def match_domain5(expanded_url):\n",
    "    if isinstance(expanded_url, str):  \n",
    "        for domain in domain_list5:\n",
    "            \n",
    "            if isinstance(domain, str) and domain == expanded_url:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "df_fake_general = merge_csv(\"/disk/mnemo/users/randomuser/USA Influence Opearations/Fake Website Scrape/Website Dataset/List of fake news websites - Wikipedia\")\n",
    "\n",
    "df_fake_general['Domain'] = df_fake_general['Domain'].str.lower()\n",
    "df_fake_general['Domain'] = df_fake_general['Domain'].str.replace(r'[.]', '.')\n",
    "domain_list5 = df_fake_general.Domain.to_list()\n",
    "df_URL_gen['domain_match_fake_general_website'] = False\n",
    "df_URL_gen['domain_match_fake_general_website'] = df_URL_gen['Tweet_Link_2'].apply(match_domain5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adb94b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_fake_russia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ec49e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_cluster = df_URL_gen.loc[df_URL_gen.domain_match_fake_general_website == True].groupby('Cluster_ID').count().reset_index().Cluster_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c654fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen[df_URL_gen.Cluster_ID.isin(fake_news_cluster)].drop_duplicates('Cluster_ID').to_csv('Fake_Website_Cluster_2024.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de185f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qq = df_URL_gen[df_URL_gen.Cluster_ID.isin(fake_news_cluster)].drop_duplicates('Cluster_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f017d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qq.loc[df_qq.Cluster_ID == '2464']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1fa044",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def match_domain6(expanded_url):\n",
    "    if isinstance(expanded_url, str):\n",
    "        for domain in domain_list6:\n",
    "            \n",
    "            if isinstance(domain, str) and domain == expanded_url:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "df_fake_russia = merge_csv(\"/disk/mnemo/users/randomuser/USA Influence Opearations/Fake Website Scrape/Website Dataset/List of political disinformation website campaigns in Russia-Wikipedia\")\n",
    "\n",
    "df_fake_russia['Domain'] = df_fake_russia['Domain'].str.lower()\n",
    "df_fake_russia['Domain'] = df_fake_russia['Domain'].str.replace(r'[.]', '.')\n",
    "domain_list6 = df_fake_russia.Domain.to_list()\n",
    "df_URL_gen['domain_match_fake_russia_website'] = False\n",
    "df_URL_gen['domain_match_fake_russia_website'] = df_URL_gen['Tweet_Link_2'].apply(match_domain6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2042f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa2cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen.loc[df_URL_gen.domain_match_fake_russia_website == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef3b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen.loc[df_URL_gen.domain_match_fake_russia_website == True].groupby('Tweet_Link_2').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f8bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def match_domain7(expanded_url):\n",
    "    if isinstance(expanded_url, str):  # Ensure expanded_url is a string\n",
    "        for domain in domain_list7:\n",
    "            \n",
    "            if isinstance(domain, str) and domain == expanded_url:  # Ensure domain is a string\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "df_troll_website = merge_csv(\"/disk/mnemo/users/randomuser/USA Influence Opearations/Fake Website Scrape/Website Dataset/List of fake news troll farms-Wikipedia\")\n",
    "\n",
    "df_troll_website['Domain'] = df_troll_website['Domain'].str.lower()\n",
    "df_troll_website['Domain'] = df_troll_website['Domain'].str.replace(r'[.]', '.')\n",
    "domain_list7 = df_troll_website.Domain.to_list()\n",
    "df_URL_gen['domain_match_troll_website'] = False\n",
    "df_URL_gen['domain_match_troll_website'] = df_URL_gen['Tweet_Link_2'].apply(match_domain7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbbed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen.loc[df_URL_gen.domain_match_troll_website == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04c00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04bd58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen.groupby('domain_match_troll_website').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9992cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_URL_gen.loc[df_URL_gen.domain_match_Biased_Websites == True]))\n",
    "print(len(df_URL_gen.loc[df_URL_gen.domain_match_Biased_Websites == True].groupby('User_ID').count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_URL_gen.loc[(df_URL_gen.domain_match_fake_general_website == True)|\n",
    "                         (df_URL_gen.domain_match_fake_International_website == True)|\n",
    "                        (df_URL_gen.domain_match_fake_russia_website == True)|\n",
    "                        (df_URL_gen.domain_match_fake_USA_website == True)|\n",
    "                        (df_URL_gen.domain_match_Biased_Websites == True)].groupby('User_ID').count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d99192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sus = df_URL_gen.loc[(df_URL_gen.domain_match_fake_general_website == True)|\n",
    "                         (df_URL_gen.domain_match_fake_International_website == True)|\n",
    "                        (df_URL_gen.domain_match_fake_russia_website == True)|\n",
    "                        (df_URL_gen.domain_match_fake_USA_website == True)|\n",
    "                        (df_URL_gen.domain_match_Biased_Websites == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808ad96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen.loc[df_URL_gen.domain_match_fake_general_website == True].groupby('Cluster_ID').count().reset_index().Cluster_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c82b55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sus.groupby('User_ID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154483e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campaign = pd.read_csv('All_Cluster_Tweet_Topic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c27de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campaign[['Cluster_ID', 'Tweet_ID']].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ae5030",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen2 = pd.merge(df_sus, df_campaign[['Cluster_ID', 'Tweet_ID']].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e61b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campaign.Tweet_ID.astype('str').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e36d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sus.groupby('Tweet_Link_2').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9d481",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen2.groupby('Cluster_ID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab74d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen2.loc[(df_URL_gen2.domain_match_fake_general_website == True)|\n",
    "                         (df_URL_gen2.domain_match_fake_International_website == True)|\n",
    "                        (df_URL_gen2.domain_match_fake_russia_website == True)|\n",
    "                        (df_URL_gen2.domain_match_fake_USA_website == True)].groupby('Cluster_ID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143aa1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen2.loc[(df_URL_gen2.domain_match_fake_general_website == True)|\n",
    "                         (df_URL_gen2.domain_match_fake_International_website == True)|\n",
    "                        (df_URL_gen2.domain_match_fake_russia_website == True)|\n",
    "                        (df_URL_gen2.domain_match_fake_USA_website == True)].groupby('Tweet_Link_2').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b010ec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_URL_gen2.loc[(df_URL_gen2.domain_match_fake_general_website == True)|\n",
    "                         (df_URL_gen2.domain_match_fake_International_website == True)|\n",
    "                        (df_URL_gen2.domain_match_fake_russia_website == True)|\n",
    "                        (df_URL_gen2.domain_match_fake_USA_website == True)].groupby('Cluster_ID').count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da9399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_URL_gen2.loc[(df_URL_gen2.domain_match_fake_general_website == True)|\n",
    "                         (df_URL_gen2.domain_match_fake_International_website == True)|\n",
    "                        (df_URL_gen2.domain_match_fake_russia_website == True)|\n",
    "                        (df_URL_gen2.domain_match_fake_USA_website == True)].groupby('Cluster_ID').count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa53486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(domain_list + domain_list2 + domain_list3 + domain_list4 + domain_list5 + domain_list6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b0e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen2.groupby('User_ID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50181173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen2.loc[df_URL_gen2.Tweet_Link_2 == 'firstpost.com'].groupby('Cluster_ID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2f2f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen2.groupby('Tweet_Link_2').count().sort_values('Tweet_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f723a6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URL_gen.groupby('Tweet_Link_2').count().sort_values('Tweet_ID')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
