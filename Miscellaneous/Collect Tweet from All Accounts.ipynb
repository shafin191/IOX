{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab36f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import tweepy\n",
    "import pickle\n",
    "import time\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02652516",
   "metadata": {},
   "outputs": [],
   "source": [
    "key1 = \"\"\n",
    "key2 = \"\"\n",
    "key3 = \"\"\n",
    "key4 = \"\"\n",
    "\n",
    "\n",
    "auth = tweepy.OAuthHandler(key1, key2)\n",
    "auth.set_access_token(key3, key4)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ab95a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('U:\\Twitter Research\\Fake News Scraping\\All_Fake_without_debunkers_Updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f46b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "newid = df.User_ID.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39130d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = 0\n",
    "old_length = 0\n",
    "new_length =0\n",
    "consumer_key = key1\n",
    "consumer_secret = key2\n",
    "access_key = key3\n",
    "access_secret = key4\n",
    "err = []\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "for i in newid:\n",
    "    alltweets = []\n",
    "    try:\n",
    "        new_tweets = api.user_timeline(user_id = i,count=200, tweet_mode=\"extended\")\n",
    "    except:\n",
    "        print('Error: '+ str(i))\n",
    "        err.append(i)\n",
    "        continue\n",
    "\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "    try:\n",
    "        oldest = alltweets[-1].id - 1\n",
    "    except:\n",
    "        print('Error: '+ str(i))\n",
    "        err.append(i)\n",
    "        continue\n",
    "\n",
    "\n",
    "    while len(new_tweets) > 0:\n",
    "        try:\n",
    "            new_tweets = api.user_timeline(user_id = i,count=200,max_id=oldest, tweet_mode=\"extended\")\n",
    "        except:\n",
    "            print('Error: '+ str(i))\n",
    "            err.append(i)\n",
    "            continue\n",
    "\n",
    "        alltweets.extend(new_tweets)\n",
    "\n",
    "        try:\n",
    "            oldest = alltweets[-1].id - 1\n",
    "        except:\n",
    "            print('Error: '+ str(i))\n",
    "            err.append(i)\n",
    "            continue\n",
    "        \n",
    "    with open('U:/Twitter Research/Fake News Scraping/Tweet_Collection_May_6th/'+str(i) +'.data', 'wb') as filehandle:\n",
    "        pickle.dump(alltweets, filehandle)\n",
    "\n",
    "    new_length = len(alltweets)\n",
    "    print(f\"...{new_length} tweets downloaded so far for {i}\")\n",
    "    print(str(it))\n",
    "    it+=1\n",
    "    if (it%25==0):\n",
    "        time.sleep(15*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3866e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
