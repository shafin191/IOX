{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2726df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import tweepy\n",
    "import pickle\n",
    "import time\n",
    "pd.set_option('display.max_columns', None)  \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef38a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "key1 = \"\"\n",
    "key2 = \"\"\n",
    "key3 = \"\"\n",
    "key4 = \"\"\n",
    "\n",
    "\n",
    "auth = tweepy.OAuthHandler(key1, key2)\n",
    "auth.set_access_token(key3, key4)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65800031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f6737e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = api.get_user(user_id = eid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef26a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "327616f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e73140d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =  pd.read_csv('U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor_Multi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9953498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = api.get_user(screen_name = df1.Screen_Name[0])\n",
    "\n",
    "ID = user.id_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06e60f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Screen_Name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33b33133",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id1 = []\n",
    "screen_name1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74027db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df1.Screen_Name:\n",
    "    try:\n",
    "        user = api.get_user(screen_name = i)\n",
    "        ID = user.id_str\n",
    "        user_id1.append(ID)\n",
    "        screen_name1.append(i)\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45e2069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(screen_name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba2aa216",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor1 = pd.DataFrame(\n",
    "    {'ScreenName': screen_name1,\n",
    "     'UserID': user_id1,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e56ac7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d01705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a275f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id2 = []\n",
    "screen_name2 = []\n",
    "for i in df2.ScreenName:\n",
    "    try:\n",
    "        user = api.get_user(screen_name = i)\n",
    "        ID = user.id_str\n",
    "        user_id2.append(ID)\n",
    "        screen_name2.append(i)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d3acadf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "31b165d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_multi = pd.DataFrame(\n",
    "    {'ScreenName': screen_name2,\n",
    "     'UserID': user_id2,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8be00738",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68cb2def",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor1.to_csv('U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor1_UserID.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b204d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_multi.to_csv('U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor_Multi_User_ID.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7bf3e7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20b29bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a588c7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f66d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4cdcca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc5dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor1 = pd.read_csv('U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor1_UserID.csv')\n",
    "monitor_multi = pd.read_csv('U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor_Multi_User_ID.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fc5bda85",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(monitor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "77c6e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(monitor_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8734f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d9932d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,30):\n",
    "    from datetime import date\n",
    "    today = date.today()\n",
    "    date = today.strftime(\"%b_%d\")\n",
    "    print(date)\n",
    "\n",
    "    newpath = r'U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor1_Tweets_'+ date \n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "\n",
    "    newpath = r'U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor_Multi_Tweets_'+ date \n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "\n",
    "    monitor1_error = []\n",
    "    k = 0\n",
    "    for i in monitor1.UserID:\n",
    "        try:\n",
    "            tweets = api.user_timeline(user_id = i, count=200,\n",
    "                               tweet_mode='extended', exclude_replies=False, include_rts=False)\n",
    "            file_name = 'U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor1_Tweets_'+ str(date) + '\\\\' +str(i) +'.data'\n",
    "            with open(file_name, 'wb') as filehandle:\n",
    "                pickle.dump(tweets, filehandle)\n",
    "        except:\n",
    "            monitor1_error.append(i)\n",
    "            print(i)\n",
    "        time.sleep(30)\n",
    "\n",
    "\n",
    "    file = open('U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor1_Tweets_' + date + '\\Suspended.txt','w')\n",
    "    for item in monitor1_error:\n",
    "        file.write(str(item) + \"\\n\")\n",
    "    file.close()\n",
    "\n",
    "\n",
    "    monitor_multi_error = []\n",
    "    k = 0\n",
    "    for i in monitor_multi.UserID:\n",
    "        try:\n",
    "            tweets = api.user_timeline(user_id = i, count=200,\n",
    "                               tweet_mode='extended', exclude_replies=False, include_rts=False)\n",
    "            file_name = 'U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor_Multi_Tweets_'+ str(date) + '\\\\' +str(i) +'.data'\n",
    "            with open(file_name, 'wb') as filehandle:\n",
    "                pickle.dump(tweets, filehandle)\n",
    "        except:\n",
    "            monitor_multi_error.append(i)\n",
    "            print(i)\n",
    "\n",
    "        time.sleep(30)\n",
    "\n",
    "\n",
    "    file = open('U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor_Multi_Tweets_' + date + '\\Suspended.txt','w')\n",
    "    for item in monitor_multi_error:\n",
    "        file.write(str(item) + \"\\n\")\n",
    "    file.close()\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "772fd4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "newpath = r'U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor1_Tweets_'+ date \n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "    \n",
    "newpath = r'U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor_Multi_Tweets_'+ date \n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9a4ebc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor1_error = []\n",
    "k = 0\n",
    "for i in monitor1.UserID:\n",
    "    try:\n",
    "        tweets = api.user_timeline(user_id = i, count=200,\n",
    "                           tweet_mode='extended', exclude_replies=False, include_rts=False)\n",
    "        file_name = 'U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor1_Tweets_'+ str(date) + '\\\\' +str(i) +'.data'\n",
    "        with open(file_name, 'wb') as filehandle:\n",
    "            pickle.dump(tweets, filehandle)\n",
    "    except:\n",
    "        monitor1_error.append(i)\n",
    "        print(i)\n",
    "    time.sleep(30)\n",
    "\n",
    "    \n",
    "file = open('U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor1_Tweets_' + date + '\\Suspended.txt','w')\n",
    "for item in monitor1_error:\n",
    "    file.write(str(item) + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cda88453",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_multi_error = []\n",
    "k = 0\n",
    "for i in monitor_multi.UserID:\n",
    "    try:\n",
    "        tweets = api.user_timeline(user_id = i, count=200,\n",
    "                           tweet_mode='extended', exclude_replies=False, include_rts=False)\n",
    "        file_name = 'U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor_Multi_Tweets_'+ str(date) + '\\\\' +str(i) +'.data'\n",
    "        with open(file_name, 'wb') as filehandle:\n",
    "            pickle.dump(tweets, filehandle)\n",
    "    except:\n",
    "        monitor_multi_error.append(i)\n",
    "        print(i)\n",
    "        \n",
    "    time.sleep(30)\n",
    "\n",
    "    \n",
    "file = open('U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor_Multi_Tweets_' + date + '\\Suspended.txt','w')\n",
    "for item in monitor_multi_error:\n",
    "    file.write(str(item) + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d8db049",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('U:\\Twitter Research\\Fake News Scraping\\Monitoring Accounts\\Monitor1_Tweets_' + date + '\\Suspended.txt','w')\n",
    "for item in monitor1_error:\n",
    "    file.write(str(item) + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86780b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
